{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler, MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_insurance_claims = pd.read_csv(\"./Insurance_claims.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReferenceId</th>\n",
       "      <th>PolicyholderNumber</th>\n",
       "      <th>FirstPartyVehicleNumber</th>\n",
       "      <th>ThirdPartyVehicleNumber</th>\n",
       "      <th>InsurerNotes</th>\n",
       "      <th>PolicyholderOccupation</th>\n",
       "      <th>LossDate</th>\n",
       "      <th>FirstPolicySubscriptionDate</th>\n",
       "      <th>ClaimCause</th>\n",
       "      <th>ClaimInvolvedCovers</th>\n",
       "      <th>...</th>\n",
       "      <th>NumberOfPoliciesOfPolicyholder</th>\n",
       "      <th>FpVehicleAgeMonths</th>\n",
       "      <th>EasinessToStage</th>\n",
       "      <th>ClaimWihoutIdentifiedThirdParty</th>\n",
       "      <th>ClaimAmount</th>\n",
       "      <th>LossHour</th>\n",
       "      <th>PolicyHolderAge</th>\n",
       "      <th>NumberOfBodilyInjuries</th>\n",
       "      <th>FirstPartyLiability</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4842</td>\n",
       "      <td>531112</td>\n",
       "      <td>715507.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>avoids a cat and hits a garage pole With deduc...</td>\n",
       "      <td>CivilServant</td>\n",
       "      <td>1/2/19</td>\n",
       "      <td>6/18/18</td>\n",
       "      <td>CollisionWithAnimal</td>\n",
       "      <td>MaterialDamages ActLiability</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>4624.73</td>\n",
       "      <td>8.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4844</td>\n",
       "      <td>87170</td>\n",
       "      <td>71164.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>accident only expert contacts us to inform us ...</td>\n",
       "      <td>Worker</td>\n",
       "      <td>1/2/19</td>\n",
       "      <td>6/29/17</td>\n",
       "      <td>LossOfControl</td>\n",
       "      <td>MaterialDamages ActLiability</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>230.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1606.81</td>\n",
       "      <td>11.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4848</td>\n",
       "      <td>98706</td>\n",
       "      <td>442609.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ae Miss/ for garage change A/ setting up EAD/ ...</td>\n",
       "      <td>Worker</td>\n",
       "      <td>1/2/19</td>\n",
       "      <td>2/5/17</td>\n",
       "      <td>AccidentWithIdentifiedThirdParty</td>\n",
       "      <td>MaterialDamages ActLiability</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>998.20</td>\n",
       "      <td>18.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4849</td>\n",
       "      <td>38240</td>\n",
       "      <td>24604.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>awaiting report to determine rc, no box checke...</td>\n",
       "      <td>CivilServant</td>\n",
       "      <td>1/2/19</td>\n",
       "      <td>1/21/17</td>\n",
       "      <td>AccidentWithIdentifiedThirdParty</td>\n",
       "      <td>MaterialDamages ActLiability ReplacementVehicle</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>2506.92</td>\n",
       "      <td>11.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4850</td>\n",
       "      <td>11339</td>\n",
       "      <td>2933.0</td>\n",
       "      <td>229134.0</td>\n",
       "      <td>Insured in THIRD-PARTY formula Insured in a su...</td>\n",
       "      <td>Farmer</td>\n",
       "      <td>1/2/19</td>\n",
       "      <td>1/13/18</td>\n",
       "      <td>AccidentWithIdentifiedThirdParty</td>\n",
       "      <td>ActLiability</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>12.00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ReferenceId  PolicyholderNumber  FirstPartyVehicleNumber  \\\n",
       "0         4842              531112                 715507.0   \n",
       "1         4844               87170                  71164.0   \n",
       "2         4848               98706                 442609.0   \n",
       "3         4849               38240                  24604.0   \n",
       "4         4850               11339                   2933.0   \n",
       "\n",
       "   ThirdPartyVehicleNumber                                       InsurerNotes  \\\n",
       "0                      NaN  avoids a cat and hits a garage pole With deduc...   \n",
       "1                      NaN  accident only expert contacts us to inform us ...   \n",
       "2                      NaN  ae Miss/ for garage change A/ setting up EAD/ ...   \n",
       "3                      NaN  awaiting report to determine rc, no box checke...   \n",
       "4                 229134.0  Insured in THIRD-PARTY formula Insured in a su...   \n",
       "\n",
       "  PolicyholderOccupation LossDate FirstPolicySubscriptionDate  \\\n",
       "0           CivilServant   1/2/19                     6/18/18   \n",
       "1                 Worker   1/2/19                     6/29/17   \n",
       "2                 Worker   1/2/19                      2/5/17   \n",
       "3           CivilServant   1/2/19                     1/21/17   \n",
       "4                 Farmer   1/2/19                     1/13/18   \n",
       "\n",
       "                         ClaimCause  \\\n",
       "0               CollisionWithAnimal   \n",
       "1                     LossOfControl   \n",
       "2  AccidentWithIdentifiedThirdParty   \n",
       "3  AccidentWithIdentifiedThirdParty   \n",
       "4  AccidentWithIdentifiedThirdParty   \n",
       "\n",
       "                               ClaimInvolvedCovers  ...  \\\n",
       "0                     MaterialDamages ActLiability  ...   \n",
       "1                     MaterialDamages ActLiability  ...   \n",
       "2                     MaterialDamages ActLiability  ...   \n",
       "3  MaterialDamages ActLiability ReplacementVehicle  ...   \n",
       "4                                     ActLiability  ...   \n",
       "\n",
       "  NumberOfPoliciesOfPolicyholder FpVehicleAgeMonths EasinessToStage  \\\n",
       "0                              1              104.0            0.25   \n",
       "1                              3              230.0            0.50   \n",
       "2                              9               93.0            0.25   \n",
       "3                              2               56.0            0.25   \n",
       "4                              4              110.0            0.25   \n",
       "\n",
       "  ClaimWihoutIdentifiedThirdParty ClaimAmount  LossHour  PolicyHolderAge  \\\n",
       "0                               1     4624.73       8.0             45.0   \n",
       "1                               1     1606.81      11.0             20.0   \n",
       "2                               0      998.20      18.0             32.0   \n",
       "3                               0     2506.92      11.0             46.0   \n",
       "4                               0       12.00      12.0             28.0   \n",
       "\n",
       "   NumberOfBodilyInjuries  FirstPartyLiability  Fraud  \n",
       "0                       0                  1.0      0  \n",
       "1                       0                  1.0      0  \n",
       "2                       0                  0.5      0  \n",
       "3                       0                  0.5      0  \n",
       "4                       0                  0.0      0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_insurance_claims.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11530 entries, 0 to 11529\n",
      "Data columns (total 26 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   ReferenceId                      11530 non-null  int64  \n",
      " 1   PolicyholderNumber               11530 non-null  int64  \n",
      " 2   FirstPartyVehicleNumber          11035 non-null  float64\n",
      " 3   ThirdPartyVehicleNumber          379 non-null    float64\n",
      " 4   InsurerNotes                     9173 non-null   object \n",
      " 5   PolicyholderOccupation           11187 non-null  object \n",
      " 6   LossDate                         11530 non-null  object \n",
      " 7   FirstPolicySubscriptionDate      11530 non-null  object \n",
      " 8   ClaimCause                       11333 non-null  object \n",
      " 9   ClaimInvolvedCovers              11335 non-null  object \n",
      " 10  DamageImportance                 738 non-null    object \n",
      " 11  FirstPartyVehicleType            11518 non-null  object \n",
      " 12  ConnectionBetweenParties         98 non-null     object \n",
      " 13  LossPostCode                     10122 non-null  object \n",
      " 14  PolicyHolderPostCode             11530 non-null  object \n",
      " 15  PolicyWasSubscribedOnInternet    11530 non-null  int64  \n",
      " 16  NumberOfPoliciesOfPolicyholder   11530 non-null  int64  \n",
      " 17  FpVehicleAgeMonths               11518 non-null  float64\n",
      " 18  EasinessToStage                  11530 non-null  float64\n",
      " 19  ClaimWihoutIdentifiedThirdParty  11530 non-null  int64  \n",
      " 20  ClaimAmount                      11530 non-null  float64\n",
      " 21  LossHour                         11436 non-null  float64\n",
      " 22  PolicyHolderAge                  11494 non-null  float64\n",
      " 23  NumberOfBodilyInjuries           11530 non-null  int64  \n",
      " 24  FirstPartyLiability              11530 non-null  float64\n",
      " 25  Fraud                            11530 non-null  int64  \n",
      "dtypes: float64(8), int64(7), object(11)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_insurance_claims.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReferenceId                            0\n",
       "PolicyholderNumber                     0\n",
       "FirstPartyVehicleNumber              495\n",
       "ThirdPartyVehicleNumber            11151\n",
       "InsurerNotes                        2357\n",
       "PolicyholderOccupation               343\n",
       "LossDate                               0\n",
       "FirstPolicySubscriptionDate            0\n",
       "ClaimCause                           197\n",
       "ClaimInvolvedCovers                  195\n",
       "DamageImportance                   10792\n",
       "FirstPartyVehicleType                 12\n",
       "ConnectionBetweenParties           11432\n",
       "LossPostCode                        1408\n",
       "PolicyHolderPostCode                   0\n",
       "PolicyWasSubscribedOnInternet          0\n",
       "NumberOfPoliciesOfPolicyholder         0\n",
       "FpVehicleAgeMonths                    12\n",
       "EasinessToStage                        0\n",
       "ClaimWihoutIdentifiedThirdParty        0\n",
       "ClaimAmount                            0\n",
       "LossHour                              94\n",
       "PolicyHolderAge                       36\n",
       "NumberOfBodilyInjuries                 0\n",
       "FirstPartyLiability                    0\n",
       "Fraud                                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_insurance_claims.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FirstPartyVehicleNumber',\n",
       " 'ThirdPartyVehicleNumber',\n",
       " 'InsurerNotes',\n",
       " 'PolicyholderOccupation',\n",
       " 'ClaimCause',\n",
       " 'ClaimInvolvedCovers',\n",
       " 'DamageImportance',\n",
       " 'FirstPartyVehicleType',\n",
       " 'ConnectionBetweenParties',\n",
       " 'LossPostCode',\n",
       " 'FpVehicleAgeMonths',\n",
       " 'LossHour',\n",
       " 'PolicyHolderAge']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_cols = df_insurance_claims.columns[df_insurance_claims.isna().any()].tolist()\n",
    "nan_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking the correlations of Fraud status with other features\n",
    "df_insurance_claims.corr(method ='pearson')\n",
    "\n",
    "# Checking the correlations via the correlation heatmap\n",
    "sns.heatmap(df_insurance_claims.corr(), cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReferenceId</th>\n",
       "      <th>PolicyholderNumber</th>\n",
       "      <th>FirstPartyVehicleNumber</th>\n",
       "      <th>ThirdPartyVehicleNumber</th>\n",
       "      <th>InsurerNotes</th>\n",
       "      <th>PolicyholderOccupation</th>\n",
       "      <th>LossDate</th>\n",
       "      <th>FirstPolicySubscriptionDate</th>\n",
       "      <th>ClaimCause</th>\n",
       "      <th>ClaimInvolvedCovers</th>\n",
       "      <th>...</th>\n",
       "      <th>NumberOfPoliciesOfPolicyholder</th>\n",
       "      <th>FpVehicleAgeMonths</th>\n",
       "      <th>EasinessToStage</th>\n",
       "      <th>ClaimWihoutIdentifiedThirdParty</th>\n",
       "      <th>ClaimAmount</th>\n",
       "      <th>LossHour</th>\n",
       "      <th>PolicyHolderAge</th>\n",
       "      <th>NumberOfBodilyInjuries</th>\n",
       "      <th>FirstPartyLiability</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4842</td>\n",
       "      <td>531112</td>\n",
       "      <td>715507.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>avoids a cat and hits a garage pole With deduc...</td>\n",
       "      <td>CivilServant</td>\n",
       "      <td>1/2/19</td>\n",
       "      <td>6/18/18</td>\n",
       "      <td>CollisionWithAnimal</td>\n",
       "      <td>MaterialDamages ActLiability</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>4624.73</td>\n",
       "      <td>8.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4844</td>\n",
       "      <td>87170</td>\n",
       "      <td>71164.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>accident only expert contacts us to inform us ...</td>\n",
       "      <td>Worker</td>\n",
       "      <td>1/2/19</td>\n",
       "      <td>6/29/17</td>\n",
       "      <td>LossOfControl</td>\n",
       "      <td>MaterialDamages ActLiability</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>230.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1606.81</td>\n",
       "      <td>11.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4848</td>\n",
       "      <td>98706</td>\n",
       "      <td>442609.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ae Miss/ for garage change A/ setting up EAD/ ...</td>\n",
       "      <td>Worker</td>\n",
       "      <td>1/2/19</td>\n",
       "      <td>2/5/17</td>\n",
       "      <td>AccidentWithIdentifiedThirdParty</td>\n",
       "      <td>MaterialDamages ActLiability</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>998.20</td>\n",
       "      <td>18.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4849</td>\n",
       "      <td>38240</td>\n",
       "      <td>24604.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>awaiting report to determine rc, no box checke...</td>\n",
       "      <td>CivilServant</td>\n",
       "      <td>1/2/19</td>\n",
       "      <td>1/21/17</td>\n",
       "      <td>AccidentWithIdentifiedThirdParty</td>\n",
       "      <td>MaterialDamages ActLiability ReplacementVehicle</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>2506.92</td>\n",
       "      <td>11.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4850</td>\n",
       "      <td>11339</td>\n",
       "      <td>2933.0</td>\n",
       "      <td>229134.0</td>\n",
       "      <td>Insured in THIRD-PARTY formula Insured in a su...</td>\n",
       "      <td>Farmer</td>\n",
       "      <td>1/2/19</td>\n",
       "      <td>1/13/18</td>\n",
       "      <td>AccidentWithIdentifiedThirdParty</td>\n",
       "      <td>ActLiability</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>12.00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11525</th>\n",
       "      <td>16378</td>\n",
       "      <td>452486</td>\n",
       "      <td>626487.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Employee</td>\n",
       "      <td>2/17/21</td>\n",
       "      <td>3/15/19</td>\n",
       "      <td>WindscreenDamage</td>\n",
       "      <td>Windscreen</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1010.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11526</th>\n",
       "      <td>16379</td>\n",
       "      <td>581104</td>\n",
       "      <td>788178.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Employee</td>\n",
       "      <td>3/7/21</td>\n",
       "      <td>7/20/17</td>\n",
       "      <td>WindscreenDamage</td>\n",
       "      <td>Windscreen</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>154.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11527</th>\n",
       "      <td>16380</td>\n",
       "      <td>817231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Employee</td>\n",
       "      <td>3/15/21</td>\n",
       "      <td>9/30/20</td>\n",
       "      <td>WindscreenDamage</td>\n",
       "      <td>Windscreen</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>139.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>420.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11528</th>\n",
       "      <td>16381</td>\n",
       "      <td>321534</td>\n",
       "      <td>468522.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CivilServant</td>\n",
       "      <td>3/6/21</td>\n",
       "      <td>12/28/18</td>\n",
       "      <td>WindscreenDamage</td>\n",
       "      <td>Windscreen</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>96.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11529</th>\n",
       "      <td>16382</td>\n",
       "      <td>399916</td>\n",
       "      <td>615052.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Employee</td>\n",
       "      <td>3/13/21</td>\n",
       "      <td>3/1/17</td>\n",
       "      <td>WindscreenDamage</td>\n",
       "      <td>Windscreen</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>223.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11530 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ReferenceId  PolicyholderNumber  FirstPartyVehicleNumber  \\\n",
       "0             4842              531112                 715507.0   \n",
       "1             4844               87170                  71164.0   \n",
       "2             4848               98706                 442609.0   \n",
       "3             4849               38240                  24604.0   \n",
       "4             4850               11339                   2933.0   \n",
       "...            ...                 ...                      ...   \n",
       "11525        16378              452486                 626487.0   \n",
       "11526        16379              581104                 788178.0   \n",
       "11527        16380              817231                      NaN   \n",
       "11528        16381              321534                 468522.0   \n",
       "11529        16382              399916                 615052.0   \n",
       "\n",
       "       ThirdPartyVehicleNumber  \\\n",
       "0                          NaN   \n",
       "1                          NaN   \n",
       "2                          NaN   \n",
       "3                          NaN   \n",
       "4                     229134.0   \n",
       "...                        ...   \n",
       "11525                      NaN   \n",
       "11526                      NaN   \n",
       "11527                      NaN   \n",
       "11528                      NaN   \n",
       "11529                      NaN   \n",
       "\n",
       "                                            InsurerNotes  \\\n",
       "0      avoids a cat and hits a garage pole With deduc...   \n",
       "1      accident only expert contacts us to inform us ...   \n",
       "2      ae Miss/ for garage change A/ setting up EAD/ ...   \n",
       "3      awaiting report to determine rc, no box checke...   \n",
       "4      Insured in THIRD-PARTY formula Insured in a su...   \n",
       "...                                                  ...   \n",
       "11525                                                NaN   \n",
       "11526                                                NaN   \n",
       "11527                                                NaN   \n",
       "11528                                                NaN   \n",
       "11529                                                NaN   \n",
       "\n",
       "      PolicyholderOccupation LossDate FirstPolicySubscriptionDate  \\\n",
       "0               CivilServant   1/2/19                     6/18/18   \n",
       "1                     Worker   1/2/19                     6/29/17   \n",
       "2                     Worker   1/2/19                      2/5/17   \n",
       "3               CivilServant   1/2/19                     1/21/17   \n",
       "4                     Farmer   1/2/19                     1/13/18   \n",
       "...                      ...      ...                         ...   \n",
       "11525               Employee  2/17/21                     3/15/19   \n",
       "11526               Employee   3/7/21                     7/20/17   \n",
       "11527               Employee  3/15/21                     9/30/20   \n",
       "11528           CivilServant   3/6/21                    12/28/18   \n",
       "11529               Employee  3/13/21                      3/1/17   \n",
       "\n",
       "                             ClaimCause  \\\n",
       "0                   CollisionWithAnimal   \n",
       "1                         LossOfControl   \n",
       "2      AccidentWithIdentifiedThirdParty   \n",
       "3      AccidentWithIdentifiedThirdParty   \n",
       "4      AccidentWithIdentifiedThirdParty   \n",
       "...                                 ...   \n",
       "11525                  WindscreenDamage   \n",
       "11526                  WindscreenDamage   \n",
       "11527                  WindscreenDamage   \n",
       "11528                  WindscreenDamage   \n",
       "11529                  WindscreenDamage   \n",
       "\n",
       "                                   ClaimInvolvedCovers  ...  \\\n",
       "0                         MaterialDamages ActLiability  ...   \n",
       "1                         MaterialDamages ActLiability  ...   \n",
       "2                         MaterialDamages ActLiability  ...   \n",
       "3      MaterialDamages ActLiability ReplacementVehicle  ...   \n",
       "4                                         ActLiability  ...   \n",
       "...                                                ...  ...   \n",
       "11525                                       Windscreen  ...   \n",
       "11526                                       Windscreen  ...   \n",
       "11527                                       Windscreen  ...   \n",
       "11528                                       Windscreen  ...   \n",
       "11529                                       Windscreen  ...   \n",
       "\n",
       "      NumberOfPoliciesOfPolicyholder FpVehicleAgeMonths EasinessToStage  \\\n",
       "0                                  1              104.0            0.25   \n",
       "1                                  3              230.0            0.50   \n",
       "2                                  9               93.0            0.25   \n",
       "3                                  2               56.0            0.25   \n",
       "4                                  4              110.0            0.25   \n",
       "...                              ...                ...             ...   \n",
       "11525                              1               85.0            0.50   \n",
       "11526                              3              119.0            0.50   \n",
       "11527                              4              139.0            0.50   \n",
       "11528                              6              105.0            0.50   \n",
       "11529                              2              124.0            0.50   \n",
       "\n",
       "      ClaimWihoutIdentifiedThirdParty ClaimAmount  LossHour  PolicyHolderAge  \\\n",
       "0                                   1     4624.73       8.0             45.0   \n",
       "1                                   1     1606.81      11.0             20.0   \n",
       "2                                   0      998.20      18.0             32.0   \n",
       "3                                   0     2506.92      11.0             46.0   \n",
       "4                                   0       12.00      12.0             28.0   \n",
       "...                               ...         ...       ...              ...   \n",
       "11525                               1     1010.23       0.0             56.0   \n",
       "11526                               1      154.35       0.0             54.0   \n",
       "11527                               1      420.25       0.0             34.0   \n",
       "11528                               1       96.40       0.0             58.0   \n",
       "11529                               1      223.60       0.0             55.0   \n",
       "\n",
       "       NumberOfBodilyInjuries  FirstPartyLiability  Fraud  \n",
       "0                           0                  1.0      0  \n",
       "1                           0                  1.0      0  \n",
       "2                           0                  0.5      0  \n",
       "3                           0                  0.5      0  \n",
       "4                           0                  0.0      0  \n",
       "...                       ...                  ...    ...  \n",
       "11525                       0                  0.0      0  \n",
       "11526                       0                  0.0      0  \n",
       "11527                       0                  0.0      0  \n",
       "11528                       0                  0.0      0  \n",
       "11529                       0                  0.0      0  \n",
       "\n",
       "[11530 rows x 26 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pre-processing needed\n",
    "\n",
    "# Drop duplicates\n",
    "df_insurance_claims.drop_duplicates(inplace=True)\n",
    "df_insurance_claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FirstPartyVehicleNumber',\n",
       " 'ThirdPartyVehicleNumber',\n",
       " 'InsurerNotes',\n",
       " 'PolicyholderOccupation',\n",
       " 'ClaimCause',\n",
       " 'ClaimInvolvedCovers',\n",
       " 'DamageImportance',\n",
       " 'FirstPartyVehicleType',\n",
       " 'ConnectionBetweenParties',\n",
       " 'LossPostCode',\n",
       " 'FpVehicleAgeMonths',\n",
       " 'LossHour',\n",
       " 'PolicyHolderAge']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReferenceId</th>\n",
       "      <th>PolicyholderNumber</th>\n",
       "      <th>FirstPartyVehicleNumber</th>\n",
       "      <th>ThirdPartyVehicleNumber</th>\n",
       "      <th>InsurerNotes</th>\n",
       "      <th>PolicyholderOccupation</th>\n",
       "      <th>LossDate</th>\n",
       "      <th>FirstPolicySubscriptionDate</th>\n",
       "      <th>ClaimCause</th>\n",
       "      <th>ClaimInvolvedCovers</th>\n",
       "      <th>...</th>\n",
       "      <th>NumberOfPoliciesOfPolicyholder</th>\n",
       "      <th>FpVehicleAgeMonths</th>\n",
       "      <th>EasinessToStage</th>\n",
       "      <th>ClaimWihoutIdentifiedThirdParty</th>\n",
       "      <th>ClaimAmount</th>\n",
       "      <th>LossHour</th>\n",
       "      <th>PolicyHolderAge</th>\n",
       "      <th>NumberOfBodilyInjuries</th>\n",
       "      <th>FirstPartyLiability</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ReferenceId, PolicyholderNumber, FirstPartyVehicleNumber, ThirdPartyVehicleNumber, InsurerNotes, PolicyholderOccupation, LossDate, FirstPolicySubscriptionDate, ClaimCause, ClaimInvolvedCovers, DamageImportance, FirstPartyVehicleType, ConnectionBetweenParties, LossPostCode, PolicyHolderPostCode, PolicyWasSubscribedOnInternet, NumberOfPoliciesOfPolicyholder, FpVehicleAgeMonths, EasinessToStage, ClaimWihoutIdentifiedThirdParty, ClaimAmount, LossHour, PolicyHolderAge, NumberOfBodilyInjuries, FirstPartyLiability, Fraud]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 26 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if there are any claims where the vehicle numbers of the first and thrid parties are the same.\n",
    "# There are none\n",
    "df_insurance_claims.loc[df_insurance_claims[\"FirstPartyVehicleNumber\"]==df_insurance_claims['ThirdPartyVehicleNumber']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows where the columns have very few na values\n",
    "# FirstPartyVehicleNumber, PolicyholderOccupation, ClaimCause, ClaimInvolvedCovers, FirstPartyVehicleType, LossPostCode,\n",
    "# FpVehicleAgeMonths, LossHour, PolicyHolderAge\n",
    "df_insurance_claims.dropna(subset=['FirstPartyVehicleNumber', 'PolicyholderOccupation', 'ClaimCause', 'ClaimInvolvedCovers', \n",
    "                                    'FirstPartyVehicleType', 'LossPostCode', 'FpVehicleAgeMonths', 'LossHour', 'PolicyHolderAge'],\n",
    "                           inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PolicyholderNumber: Column length: 9120, unique values: 7659\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PolicyholderNumber</th>\n",
       "      <th>PolicyHolderCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>531112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87170</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98706</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11339</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11485</th>\n",
       "      <td>267178</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11486</th>\n",
       "      <td>808381</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11487</th>\n",
       "      <td>772615</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11510</th>\n",
       "      <td>555135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11513</th>\n",
       "      <td>367840</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9120 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PolicyholderNumber  PolicyHolderCount\n",
       "0                  531112                  1\n",
       "1                   87170                  2\n",
       "2                   98706                  2\n",
       "3                   38240                  1\n",
       "4                   11339                  4\n",
       "...                   ...                ...\n",
       "11485              267178                  1\n",
       "11486              808381                  1\n",
       "11487              772615                  1\n",
       "11510              555135                  1\n",
       "11513              367840                  2\n",
       "\n",
       "[9120 rows x 2 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Are the policy numbers unique, or are there any people who filed claims multiple times\n",
    "def get_uniqueness(df, column_names):\n",
    "    for column_name in column_names:\n",
    "        print(\"{}: Column length: {}, unique values: {}\".format(column_name, len(df[column_name]), df[column_name].nunique()))\n",
    "\n",
    "get_uniqueness(df_insurance_claims, [\"PolicyholderNumber\"])\n",
    "\n",
    "# Create a new column with count of claims made by the same policy holder.\n",
    "# Multiple claims by the same policy holder may likely indicate a fraud.\n",
    "counts_policy_holder = df_insurance_claims['PolicyholderNumber'].value_counts()\n",
    "df_insurance_claims[\"PolicyHolderCount\"] = df_insurance_claims[\"PolicyholderNumber\"].map(counts_policy_holder)\n",
    "df_insurance_claims[[\"PolicyholderNumber\", \"PolicyHolderCount\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column ClaimInvolvedCovers contains a space sepaated list of strings indicating the covers that the individual took\n",
    "# We convert this into onehot encoded columns\n",
    "one_hot = pd.get_dummies(df_insurance_claims[\"ClaimInvolvedCovers\"].str.split(\" \", expand=True).stack()).groupby(level=0).sum()\n",
    "df_insurance_claims = pd.concat([df_insurance_claims, one_hot], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the columns that have too many missing values and unnecessary comlumns such as Reference ID, PolicyHolderPostcode\n",
    "df_insurance_claims.drop(columns = [\"ReferenceId\",                     # unique \n",
    "                                    \"PolicyholderNumber\",              # unique\n",
    "                                    \"FirstPartyVehicleNumber\",         # unique    \n",
    "                                    \"ThirdPartyVehicleNumber\",         # unique\n",
    "                                    \"InsurerNotes\",                    # dropping for now\n",
    "                                    \"DamageImportance\",                # too many nans\n",
    "                                    # \"ConnectionBetweenParties\",        # maybe we can fill\n",
    "                                    \"LossPostCode\",                    # not necessary\n",
    "                                    \"PolicyHolderPostCode\",            # not necessary\n",
    "                                    \"ClaimInvolvedCovers\"              # already converted above\n",
    "                                    ], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_insurance_claims.fillna(value={\"ConnectionBetweenParties\": \"NoConnection\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the indices in the data\n",
    "df_insurance_claims.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Soumya\\AppData\\Local\\Temp\\ipykernel_14712\\3562087343.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_insurance_claims_t_days[\"LossDate\"] = pd.to_datetime(df_insurance_claims_t_days[\"LossDate\"])\n",
      "C:\\Users\\Soumya\\AppData\\Local\\Temp\\ipykernel_14712\\3562087343.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_insurance_claims_t_days[\"FirstPolicySubscriptionDate\"] = pd.to_datetime(df_insurance_claims_t_days[\"FirstPolicySubscriptionDate\"])\n"
     ]
    }
   ],
   "source": [
    "# Convert the dates to datetime objects\n",
    "df_insurance_claims_t_days = df_insurance_claims[[\"LossDate\", \"FirstPolicySubscriptionDate\", \"Fraud\"]]\n",
    "df_insurance_claims_t_days[\"LossDate\"] = pd.to_datetime(df_insurance_claims_t_days[\"LossDate\"])\n",
    "df_insurance_claims_t_days[\"FirstPolicySubscriptionDate\"] = pd.to_datetime(df_insurance_claims_t_days[\"FirstPolicySubscriptionDate\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 - Using a threshold on the number of days between the subscription data and the claim date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Soumya\\AppData\\Local\\Temp\\ipykernel_14712\\1156946861.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_insurance_claims_t_days[\"Days\"] = df_insurance_claims_t_days[\"LossDate\"] - df_insurance_claims_t_days[\"FirstPolicySubscriptionDate\"]\n",
      "C:\\Users\\Soumya\\AppData\\Local\\Temp\\ipykernel_14712\\1156946861.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_insurance_claims_t_days[\"Days\"] = pd.to_numeric(df_insurance_claims_t_days[\"Days\"].dt.days, downcast='integer')\n"
     ]
    }
   ],
   "source": [
    "df_insurance_claims_t_days[\"Days\"] = df_insurance_claims_t_days[\"LossDate\"] - df_insurance_claims_t_days[\"FirstPolicySubscriptionDate\"]\n",
    "df_insurance_claims_t_days[\"Days\"] = pd.to_numeric(df_insurance_claims_t_days[\"Days\"].dt.days, downcast='integer')\n",
    "df_insurance_claims_t_days = df_insurance_claims_t_days.astype({\"Days\": \"int64\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Days\n",
       "0       11\n",
       "1        4\n",
       "2        8\n",
       "3        2\n",
       "4        6\n",
       "5        4\n",
       "6        7\n",
       "7        2\n",
       "8        2\n",
       "9        2\n",
       "10       2\n",
       "11       2\n",
       "14       4\n",
       "16       2\n",
       "17       3\n",
       "18       2\n",
       "19       1\n",
       "20       1\n",
       "22       2\n",
       "23       2\n",
       "24       2\n",
       "25       1\n",
       "26       1\n",
       "28       2\n",
       "29       2\n",
       "47       1\n",
       "70       1\n",
       "71       1\n",
       "259      1\n",
       "310      1\n",
       "333      1\n",
       "436      1\n",
       "504      1\n",
       "530      1\n",
       "549      1\n",
       "563      1\n",
       "575      1\n",
       "584      1\n",
       "616      1\n",
       "685      1\n",
       "748      1\n",
       "769      1\n",
       "805      1\n",
       "810      1\n",
       "821      1\n",
       "824      1\n",
       "890      1\n",
       "928      1\n",
       "1201     1\n",
       "Name: Days, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fraud = df_insurance_claims_t_days.loc[df_insurance_claims_t_days[\"Fraud\"] == 1]\n",
    "df_fraud.groupby([\"Days\"])[\"Days\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max: 1201, min: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"max: {}, min: {}\".format(df_fraud[\"Days\"].max(), df_fraud[\"Days\"].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 0, suspicious: 30, fraud in susp: 11, detection_rate: 0.33, hit_rate: 36.67,  num true fraud: 101, num samples: 9120\n",
      "t: 1, suspicious: 54, fraud in susp: 15, detection_rate: 0.59, hit_rate: 27.78,  num true fraud: 101, num samples: 9120\n",
      "t: 2, suspicious: 72, fraud in susp: 23, detection_rate: 0.79, hit_rate: 31.94,  num true fraud: 101, num samples: 9120\n",
      "t: 3, suspicious: 86, fraud in susp: 25, detection_rate: 0.94, hit_rate: 29.07,  num true fraud: 101, num samples: 9120\n",
      "t: 4, suspicious: 120, fraud in susp: 31, detection_rate: 1.32, hit_rate: 25.83,  num true fraud: 101, num samples: 9120\n",
      "t: 5, suspicious: 145, fraud in susp: 35, detection_rate: 1.59, hit_rate: 24.14,  num true fraud: 101, num samples: 9120\n",
      "t: 6, suspicious: 171, fraud in susp: 42, detection_rate: 1.88, hit_rate: 24.56,  num true fraud: 101, num samples: 9120\n",
      "t: 7, suspicious: 193, fraud in susp: 44, detection_rate: 2.12, hit_rate: 22.8,  num true fraud: 101, num samples: 9120\n",
      "t: 8, suspicious: 213, fraud in susp: 46, detection_rate: 2.34, hit_rate: 21.6,  num true fraud: 101, num samples: 9120\n",
      "t: 9, suspicious: 226, fraud in susp: 48, detection_rate: 2.48, hit_rate: 21.24,  num true fraud: 101, num samples: 9120\n",
      "t: 10, suspicious: 235, fraud in susp: 50, detection_rate: 2.58, hit_rate: 21.28,  num true fraud: 101, num samples: 9120\n",
      "t: 11, suspicious: 249, fraud in susp: 52, detection_rate: 2.73, hit_rate: 20.88,  num true fraud: 101, num samples: 9120\n",
      "t: 12, suspicious: 271, fraud in susp: 52, detection_rate: 2.97, hit_rate: 19.19,  num true fraud: 101, num samples: 9120\n",
      "t: 13, suspicious: 281, fraud in susp: 52, detection_rate: 3.08, hit_rate: 18.51,  num true fraud: 101, num samples: 9120\n",
      "t: 14, suspicious: 299, fraud in susp: 56, detection_rate: 3.28, hit_rate: 18.73,  num true fraud: 101, num samples: 9120\n",
      "t: 15, suspicious: 313, fraud in susp: 56, detection_rate: 3.43, hit_rate: 17.89,  num true fraud: 101, num samples: 9120\n",
      "t: 16, suspicious: 327, fraud in susp: 58, detection_rate: 3.59, hit_rate: 17.74,  num true fraud: 101, num samples: 9120\n",
      "t: 17, suspicious: 347, fraud in susp: 61, detection_rate: 3.8, hit_rate: 17.58,  num true fraud: 101, num samples: 9120\n",
      "t: 18, suspicious: 362, fraud in susp: 63, detection_rate: 3.97, hit_rate: 17.4,  num true fraud: 101, num samples: 9120\n",
      "t: 19, suspicious: 371, fraud in susp: 64, detection_rate: 4.07, hit_rate: 17.25,  num true fraud: 101, num samples: 9120\n",
      "t: 20, suspicious: 392, fraud in susp: 65, detection_rate: 4.3, hit_rate: 16.58,  num true fraud: 101, num samples: 9120\n",
      "t: 21, suspicious: 405, fraud in susp: 65, detection_rate: 4.44, hit_rate: 16.05,  num true fraud: 101, num samples: 9120\n",
      "t: 22, suspicious: 418, fraud in susp: 67, detection_rate: 4.58, hit_rate: 16.03,  num true fraud: 101, num samples: 9120\n",
      "t: 23, suspicious: 433, fraud in susp: 69, detection_rate: 4.75, hit_rate: 15.94,  num true fraud: 101, num samples: 9120\n",
      "t: 24, suspicious: 444, fraud in susp: 71, detection_rate: 4.87, hit_rate: 15.99,  num true fraud: 101, num samples: 9120\n",
      "t: 25, suspicious: 458, fraud in susp: 72, detection_rate: 5.02, hit_rate: 15.72,  num true fraud: 101, num samples: 9120\n",
      "t: 26, suspicious: 472, fraud in susp: 73, detection_rate: 5.18, hit_rate: 15.47,  num true fraud: 101, num samples: 9120\n",
      "t: 27, suspicious: 481, fraud in susp: 73, detection_rate: 5.27, hit_rate: 15.18,  num true fraud: 101, num samples: 9120\n",
      "t: 28, suspicious: 496, fraud in susp: 75, detection_rate: 5.44, hit_rate: 15.12,  num true fraud: 101, num samples: 9120\n",
      "t: 29, suspicious: 514, fraud in susp: 77, detection_rate: 5.64, hit_rate: 14.98,  num true fraud: 101, num samples: 9120\n",
      "t: 30, suspicious: 533, fraud in susp: 77, detection_rate: 5.84, hit_rate: 14.45,  num true fraud: 101, num samples: 9120\n",
      "t: 31, suspicious: 546, fraud in susp: 77, detection_rate: 5.99, hit_rate: 14.1,  num true fraud: 101, num samples: 9120\n",
      "t: 32, suspicious: 556, fraud in susp: 77, detection_rate: 6.1, hit_rate: 13.85,  num true fraud: 101, num samples: 9120\n",
      "t: 33, suspicious: 567, fraud in susp: 77, detection_rate: 6.22, hit_rate: 13.58,  num true fraud: 101, num samples: 9120\n",
      "t: 34, suspicious: 576, fraud in susp: 77, detection_rate: 6.32, hit_rate: 13.37,  num true fraud: 101, num samples: 9120\n",
      "t: 35, suspicious: 585, fraud in susp: 77, detection_rate: 6.41, hit_rate: 13.16,  num true fraud: 101, num samples: 9120\n",
      "t: 36, suspicious: 594, fraud in susp: 77, detection_rate: 6.51, hit_rate: 12.96,  num true fraud: 101, num samples: 9120\n",
      "t: 37, suspicious: 607, fraud in susp: 77, detection_rate: 6.66, hit_rate: 12.69,  num true fraud: 101, num samples: 9120\n",
      "t: 38, suspicious: 616, fraud in susp: 77, detection_rate: 6.75, hit_rate: 12.5,  num true fraud: 101, num samples: 9120\n",
      "t: 39, suspicious: 629, fraud in susp: 77, detection_rate: 6.9, hit_rate: 12.24,  num true fraud: 101, num samples: 9120\n",
      "t: 40, suspicious: 644, fraud in susp: 77, detection_rate: 7.06, hit_rate: 11.96,  num true fraud: 101, num samples: 9120\n",
      "t: 41, suspicious: 654, fraud in susp: 77, detection_rate: 7.17, hit_rate: 11.77,  num true fraud: 101, num samples: 9120\n",
      "t: 42, suspicious: 660, fraud in susp: 77, detection_rate: 7.24, hit_rate: 11.67,  num true fraud: 101, num samples: 9120\n",
      "t: 43, suspicious: 668, fraud in susp: 77, detection_rate: 7.32, hit_rate: 11.53,  num true fraud: 101, num samples: 9120\n",
      "t: 44, suspicious: 681, fraud in susp: 77, detection_rate: 7.47, hit_rate: 11.31,  num true fraud: 101, num samples: 9120\n",
      "t: 45, suspicious: 692, fraud in susp: 77, detection_rate: 7.59, hit_rate: 11.13,  num true fraud: 101, num samples: 9120\n",
      "t: 46, suspicious: 705, fraud in susp: 77, detection_rate: 7.73, hit_rate: 10.92,  num true fraud: 101, num samples: 9120\n",
      "t: 47, suspicious: 717, fraud in susp: 78, detection_rate: 7.86, hit_rate: 10.88,  num true fraud: 101, num samples: 9120\n",
      "t: 48, suspicious: 725, fraud in susp: 78, detection_rate: 7.95, hit_rate: 10.76,  num true fraud: 101, num samples: 9120\n",
      "t: 49, suspicious: 740, fraud in susp: 78, detection_rate: 8.11, hit_rate: 10.54,  num true fraud: 101, num samples: 9120\n",
      "t: 50, suspicious: 750, fraud in susp: 78, detection_rate: 8.22, hit_rate: 10.4,  num true fraud: 101, num samples: 9120\n",
      "t: 51, suspicious: 762, fraud in susp: 78, detection_rate: 8.36, hit_rate: 10.24,  num true fraud: 101, num samples: 9120\n",
      "t: 52, suspicious: 774, fraud in susp: 78, detection_rate: 8.49, hit_rate: 10.08,  num true fraud: 101, num samples: 9120\n",
      "t: 53, suspicious: 782, fraud in susp: 78, detection_rate: 8.57, hit_rate: 9.97,  num true fraud: 101, num samples: 9120\n",
      "t: 54, suspicious: 791, fraud in susp: 78, detection_rate: 8.67, hit_rate: 9.86,  num true fraud: 101, num samples: 9120\n",
      "t: 55, suspicious: 800, fraud in susp: 78, detection_rate: 8.77, hit_rate: 9.75,  num true fraud: 101, num samples: 9120\n",
      "t: 56, suspicious: 807, fraud in susp: 78, detection_rate: 8.85, hit_rate: 9.67,  num true fraud: 101, num samples: 9120\n",
      "t: 57, suspicious: 825, fraud in susp: 78, detection_rate: 9.05, hit_rate: 9.45,  num true fraud: 101, num samples: 9120\n",
      "t: 58, suspicious: 836, fraud in susp: 78, detection_rate: 9.17, hit_rate: 9.33,  num true fraud: 101, num samples: 9120\n",
      "t: 59, suspicious: 849, fraud in susp: 78, detection_rate: 9.31, hit_rate: 9.19,  num true fraud: 101, num samples: 9120\n",
      "t: 60, suspicious: 862, fraud in susp: 78, detection_rate: 9.45, hit_rate: 9.05,  num true fraud: 101, num samples: 9120\n",
      "t: 61, suspicious: 870, fraud in susp: 78, detection_rate: 9.54, hit_rate: 8.97,  num true fraud: 101, num samples: 9120\n",
      "t: 62, suspicious: 875, fraud in susp: 78, detection_rate: 9.59, hit_rate: 8.91,  num true fraud: 101, num samples: 9120\n",
      "t: 63, suspicious: 889, fraud in susp: 78, detection_rate: 9.75, hit_rate: 8.77,  num true fraud: 101, num samples: 9120\n",
      "t: 64, suspicious: 900, fraud in susp: 78, detection_rate: 9.87, hit_rate: 8.67,  num true fraud: 101, num samples: 9120\n",
      "t: 65, suspicious: 916, fraud in susp: 78, detection_rate: 10.04, hit_rate: 8.52,  num true fraud: 101, num samples: 9120\n",
      "t: 66, suspicious: 928, fraud in susp: 78, detection_rate: 10.18, hit_rate: 8.41,  num true fraud: 101, num samples: 9120\n",
      "t: 67, suspicious: 941, fraud in susp: 78, detection_rate: 10.32, hit_rate: 8.29,  num true fraud: 101, num samples: 9120\n",
      "t: 68, suspicious: 951, fraud in susp: 78, detection_rate: 10.43, hit_rate: 8.2,  num true fraud: 101, num samples: 9120\n",
      "t: 69, suspicious: 958, fraud in susp: 78, detection_rate: 10.5, hit_rate: 8.14,  num true fraud: 101, num samples: 9120\n",
      "t: 70, suspicious: 967, fraud in susp: 79, detection_rate: 10.6, hit_rate: 8.17,  num true fraud: 101, num samples: 9120\n",
      "t: 71, suspicious: 980, fraud in susp: 80, detection_rate: 10.75, hit_rate: 8.16,  num true fraud: 101, num samples: 9120\n",
      "t: 72, suspicious: 990, fraud in susp: 80, detection_rate: 10.86, hit_rate: 8.08,  num true fraud: 101, num samples: 9120\n",
      "t: 73, suspicious: 1001, fraud in susp: 80, detection_rate: 10.98, hit_rate: 7.99,  num true fraud: 101, num samples: 9120\n",
      "t: 74, suspicious: 1012, fraud in susp: 80, detection_rate: 11.1, hit_rate: 7.91,  num true fraud: 101, num samples: 9120\n",
      "t: 75, suspicious: 1023, fraud in susp: 80, detection_rate: 11.22, hit_rate: 7.82,  num true fraud: 101, num samples: 9120\n",
      "t: 76, suspicious: 1035, fraud in susp: 80, detection_rate: 11.35, hit_rate: 7.73,  num true fraud: 101, num samples: 9120\n",
      "t: 77, suspicious: 1048, fraud in susp: 80, detection_rate: 11.49, hit_rate: 7.63,  num true fraud: 101, num samples: 9120\n",
      "t: 78, suspicious: 1055, fraud in susp: 80, detection_rate: 11.57, hit_rate: 7.58,  num true fraud: 101, num samples: 9120\n",
      "t: 79, suspicious: 1068, fraud in susp: 80, detection_rate: 11.71, hit_rate: 7.49,  num true fraud: 101, num samples: 9120\n",
      "t: 80, suspicious: 1074, fraud in susp: 80, detection_rate: 11.78, hit_rate: 7.45,  num true fraud: 101, num samples: 9120\n",
      "t: 81, suspicious: 1084, fraud in susp: 80, detection_rate: 11.89, hit_rate: 7.38,  num true fraud: 101, num samples: 9120\n",
      "t: 82, suspicious: 1094, fraud in susp: 80, detection_rate: 12.0, hit_rate: 7.31,  num true fraud: 101, num samples: 9120\n",
      "t: 83, suspicious: 1106, fraud in susp: 80, detection_rate: 12.13, hit_rate: 7.23,  num true fraud: 101, num samples: 9120\n",
      "t: 84, suspicious: 1113, fraud in susp: 80, detection_rate: 12.2, hit_rate: 7.19,  num true fraud: 101, num samples: 9120\n",
      "t: 85, suspicious: 1121, fraud in susp: 80, detection_rate: 12.29, hit_rate: 7.14,  num true fraud: 101, num samples: 9120\n",
      "t: 86, suspicious: 1132, fraud in susp: 80, detection_rate: 12.41, hit_rate: 7.07,  num true fraud: 101, num samples: 9120\n",
      "t: 87, suspicious: 1143, fraud in susp: 80, detection_rate: 12.53, hit_rate: 7.0,  num true fraud: 101, num samples: 9120\n",
      "t: 88, suspicious: 1153, fraud in susp: 80, detection_rate: 12.64, hit_rate: 6.94,  num true fraud: 101, num samples: 9120\n",
      "t: 89, suspicious: 1165, fraud in susp: 80, detection_rate: 12.77, hit_rate: 6.87,  num true fraud: 101, num samples: 9120\n",
      "t: 90, suspicious: 1177, fraud in susp: 80, detection_rate: 12.91, hit_rate: 6.8,  num true fraud: 101, num samples: 9120\n",
      "t: 91, suspicious: 1185, fraud in susp: 80, detection_rate: 12.99, hit_rate: 6.75,  num true fraud: 101, num samples: 9120\n",
      "t: 92, suspicious: 1194, fraud in susp: 80, detection_rate: 13.09, hit_rate: 6.7,  num true fraud: 101, num samples: 9120\n",
      "t: 93, suspicious: 1204, fraud in susp: 80, detection_rate: 13.2, hit_rate: 6.64,  num true fraud: 101, num samples: 9120\n",
      "t: 94, suspicious: 1219, fraud in susp: 80, detection_rate: 13.37, hit_rate: 6.56,  num true fraud: 101, num samples: 9120\n",
      "t: 95, suspicious: 1232, fraud in susp: 80, detection_rate: 13.51, hit_rate: 6.49,  num true fraud: 101, num samples: 9120\n",
      "t: 96, suspicious: 1238, fraud in susp: 80, detection_rate: 13.57, hit_rate: 6.46,  num true fraud: 101, num samples: 9120\n",
      "t: 97, suspicious: 1244, fraud in susp: 80, detection_rate: 13.64, hit_rate: 6.43,  num true fraud: 101, num samples: 9120\n",
      "t: 98, suspicious: 1255, fraud in susp: 80, detection_rate: 13.76, hit_rate: 6.37,  num true fraud: 101, num samples: 9120\n",
      "t: 99, suspicious: 1263, fraud in susp: 80, detection_rate: 13.85, hit_rate: 6.33,  num true fraud: 101, num samples: 9120\n",
      "t: 100, suspicious: 1272, fraud in susp: 80, detection_rate: 13.95, hit_rate: 6.29,  num true fraud: 101, num samples: 9120\n",
      "t: 101, suspicious: 1281, fraud in susp: 80, detection_rate: 14.05, hit_rate: 6.25,  num true fraud: 101, num samples: 9120\n",
      "t: 102, suspicious: 1290, fraud in susp: 80, detection_rate: 14.14, hit_rate: 6.2,  num true fraud: 101, num samples: 9120\n",
      "t: 103, suspicious: 1299, fraud in susp: 80, detection_rate: 14.24, hit_rate: 6.16,  num true fraud: 101, num samples: 9120\n",
      "t: 104, suspicious: 1306, fraud in susp: 80, detection_rate: 14.32, hit_rate: 6.13,  num true fraud: 101, num samples: 9120\n",
      "t: 105, suspicious: 1317, fraud in susp: 80, detection_rate: 14.44, hit_rate: 6.07,  num true fraud: 101, num samples: 9120\n",
      "t: 106, suspicious: 1332, fraud in susp: 80, detection_rate: 14.61, hit_rate: 6.01,  num true fraud: 101, num samples: 9120\n",
      "t: 107, suspicious: 1340, fraud in susp: 80, detection_rate: 14.69, hit_rate: 5.97,  num true fraud: 101, num samples: 9120\n",
      "t: 108, suspicious: 1347, fraud in susp: 80, detection_rate: 14.77, hit_rate: 5.94,  num true fraud: 101, num samples: 9120\n",
      "t: 109, suspicious: 1357, fraud in susp: 80, detection_rate: 14.88, hit_rate: 5.9,  num true fraud: 101, num samples: 9120\n",
      "t: 110, suspicious: 1366, fraud in susp: 80, detection_rate: 14.98, hit_rate: 5.86,  num true fraud: 101, num samples: 9120\n",
      "t: 111, suspicious: 1374, fraud in susp: 80, detection_rate: 15.07, hit_rate: 5.82,  num true fraud: 101, num samples: 9120\n",
      "t: 112, suspicious: 1382, fraud in susp: 80, detection_rate: 15.15, hit_rate: 5.79,  num true fraud: 101, num samples: 9120\n",
      "t: 113, suspicious: 1389, fraud in susp: 80, detection_rate: 15.23, hit_rate: 5.76,  num true fraud: 101, num samples: 9120\n",
      "t: 114, suspicious: 1401, fraud in susp: 80, detection_rate: 15.36, hit_rate: 5.71,  num true fraud: 101, num samples: 9120\n",
      "t: 115, suspicious: 1409, fraud in susp: 80, detection_rate: 15.45, hit_rate: 5.68,  num true fraud: 101, num samples: 9120\n",
      "t: 116, suspicious: 1413, fraud in susp: 80, detection_rate: 15.49, hit_rate: 5.66,  num true fraud: 101, num samples: 9120\n",
      "t: 117, suspicious: 1423, fraud in susp: 80, detection_rate: 15.6, hit_rate: 5.62,  num true fraud: 101, num samples: 9120\n",
      "t: 118, suspicious: 1434, fraud in susp: 80, detection_rate: 15.72, hit_rate: 5.58,  num true fraud: 101, num samples: 9120\n",
      "t: 119, suspicious: 1438, fraud in susp: 80, detection_rate: 15.77, hit_rate: 5.56,  num true fraud: 101, num samples: 9120\n",
      "t: 120, suspicious: 1445, fraud in susp: 80, detection_rate: 15.84, hit_rate: 5.54,  num true fraud: 101, num samples: 9120\n",
      "t: 121, suspicious: 1448, fraud in susp: 80, detection_rate: 15.88, hit_rate: 5.52,  num true fraud: 101, num samples: 9120\n",
      "t: 122, suspicious: 1457, fraud in susp: 80, detection_rate: 15.98, hit_rate: 5.49,  num true fraud: 101, num samples: 9120\n",
      "t: 123, suspicious: 1467, fraud in susp: 80, detection_rate: 16.09, hit_rate: 5.45,  num true fraud: 101, num samples: 9120\n",
      "t: 124, suspicious: 1476, fraud in susp: 80, detection_rate: 16.18, hit_rate: 5.42,  num true fraud: 101, num samples: 9120\n",
      "t: 125, suspicious: 1487, fraud in susp: 80, detection_rate: 16.3, hit_rate: 5.38,  num true fraud: 101, num samples: 9120\n",
      "t: 126, suspicious: 1500, fraud in susp: 80, detection_rate: 16.45, hit_rate: 5.33,  num true fraud: 101, num samples: 9120\n",
      "t: 127, suspicious: 1510, fraud in susp: 80, detection_rate: 16.56, hit_rate: 5.3,  num true fraud: 101, num samples: 9120\n",
      "t: 128, suspicious: 1524, fraud in susp: 80, detection_rate: 16.71, hit_rate: 5.25,  num true fraud: 101, num samples: 9120\n",
      "t: 129, suspicious: 1536, fraud in susp: 80, detection_rate: 16.84, hit_rate: 5.21,  num true fraud: 101, num samples: 9120\n",
      "t: 130, suspicious: 1544, fraud in susp: 80, detection_rate: 16.93, hit_rate: 5.18,  num true fraud: 101, num samples: 9120\n",
      "t: 131, suspicious: 1557, fraud in susp: 80, detection_rate: 17.07, hit_rate: 5.14,  num true fraud: 101, num samples: 9120\n",
      "t: 132, suspicious: 1568, fraud in susp: 80, detection_rate: 17.19, hit_rate: 5.1,  num true fraud: 101, num samples: 9120\n",
      "t: 133, suspicious: 1578, fraud in susp: 80, detection_rate: 17.3, hit_rate: 5.07,  num true fraud: 101, num samples: 9120\n",
      "t: 134, suspicious: 1583, fraud in susp: 80, detection_rate: 17.36, hit_rate: 5.05,  num true fraud: 101, num samples: 9120\n",
      "t: 135, suspicious: 1592, fraud in susp: 80, detection_rate: 17.46, hit_rate: 5.03,  num true fraud: 101, num samples: 9120\n",
      "t: 136, suspicious: 1605, fraud in susp: 80, detection_rate: 17.6, hit_rate: 4.98,  num true fraud: 101, num samples: 9120\n",
      "t: 137, suspicious: 1607, fraud in susp: 80, detection_rate: 17.62, hit_rate: 4.98,  num true fraud: 101, num samples: 9120\n",
      "t: 138, suspicious: 1613, fraud in susp: 80, detection_rate: 17.69, hit_rate: 4.96,  num true fraud: 101, num samples: 9120\n",
      "t: 139, suspicious: 1621, fraud in susp: 80, detection_rate: 17.77, hit_rate: 4.94,  num true fraud: 101, num samples: 9120\n",
      "t: 140, suspicious: 1632, fraud in susp: 80, detection_rate: 17.89, hit_rate: 4.9,  num true fraud: 101, num samples: 9120\n",
      "t: 141, suspicious: 1639, fraud in susp: 80, detection_rate: 17.97, hit_rate: 4.88,  num true fraud: 101, num samples: 9120\n",
      "t: 142, suspicious: 1645, fraud in susp: 80, detection_rate: 18.04, hit_rate: 4.86,  num true fraud: 101, num samples: 9120\n",
      "t: 143, suspicious: 1655, fraud in susp: 80, detection_rate: 18.15, hit_rate: 4.83,  num true fraud: 101, num samples: 9120\n",
      "t: 144, suspicious: 1660, fraud in susp: 80, detection_rate: 18.2, hit_rate: 4.82,  num true fraud: 101, num samples: 9120\n",
      "t: 145, suspicious: 1670, fraud in susp: 80, detection_rate: 18.31, hit_rate: 4.79,  num true fraud: 101, num samples: 9120\n",
      "t: 146, suspicious: 1681, fraud in susp: 80, detection_rate: 18.43, hit_rate: 4.76,  num true fraud: 101, num samples: 9120\n",
      "t: 147, suspicious: 1693, fraud in susp: 80, detection_rate: 18.56, hit_rate: 4.73,  num true fraud: 101, num samples: 9120\n",
      "t: 148, suspicious: 1704, fraud in susp: 80, detection_rate: 18.68, hit_rate: 4.69,  num true fraud: 101, num samples: 9120\n",
      "t: 149, suspicious: 1713, fraud in susp: 80, detection_rate: 18.78, hit_rate: 4.67,  num true fraud: 101, num samples: 9120\n",
      "t: 150, suspicious: 1725, fraud in susp: 80, detection_rate: 18.91, hit_rate: 4.64,  num true fraud: 101, num samples: 9120\n",
      "t: 151, suspicious: 1736, fraud in susp: 80, detection_rate: 19.04, hit_rate: 4.61,  num true fraud: 101, num samples: 9120\n",
      "t: 152, suspicious: 1743, fraud in susp: 80, detection_rate: 19.11, hit_rate: 4.59,  num true fraud: 101, num samples: 9120\n",
      "t: 153, suspicious: 1754, fraud in susp: 80, detection_rate: 19.23, hit_rate: 4.56,  num true fraud: 101, num samples: 9120\n",
      "t: 154, suspicious: 1762, fraud in susp: 80, detection_rate: 19.32, hit_rate: 4.54,  num true fraud: 101, num samples: 9120\n",
      "t: 155, suspicious: 1771, fraud in susp: 80, detection_rate: 19.42, hit_rate: 4.52,  num true fraud: 101, num samples: 9120\n",
      "t: 156, suspicious: 1784, fraud in susp: 80, detection_rate: 19.56, hit_rate: 4.48,  num true fraud: 101, num samples: 9120\n",
      "t: 157, suspicious: 1793, fraud in susp: 80, detection_rate: 19.66, hit_rate: 4.46,  num true fraud: 101, num samples: 9120\n",
      "t: 158, suspicious: 1799, fraud in susp: 80, detection_rate: 19.73, hit_rate: 4.45,  num true fraud: 101, num samples: 9120\n",
      "t: 159, suspicious: 1809, fraud in susp: 80, detection_rate: 19.84, hit_rate: 4.42,  num true fraud: 101, num samples: 9120\n",
      "t: 160, suspicious: 1818, fraud in susp: 80, detection_rate: 19.93, hit_rate: 4.4,  num true fraud: 101, num samples: 9120\n",
      "t: 161, suspicious: 1833, fraud in susp: 80, detection_rate: 20.1, hit_rate: 4.36,  num true fraud: 101, num samples: 9120\n",
      "t: 162, suspicious: 1842, fraud in susp: 80, detection_rate: 20.2, hit_rate: 4.34,  num true fraud: 101, num samples: 9120\n",
      "t: 163, suspicious: 1857, fraud in susp: 80, detection_rate: 20.36, hit_rate: 4.31,  num true fraud: 101, num samples: 9120\n",
      "t: 164, suspicious: 1867, fraud in susp: 80, detection_rate: 20.47, hit_rate: 4.28,  num true fraud: 101, num samples: 9120\n",
      "t: 165, suspicious: 1878, fraud in susp: 80, detection_rate: 20.59, hit_rate: 4.26,  num true fraud: 101, num samples: 9120\n",
      "t: 166, suspicious: 1892, fraud in susp: 80, detection_rate: 20.75, hit_rate: 4.23,  num true fraud: 101, num samples: 9120\n",
      "t: 167, suspicious: 1902, fraud in susp: 80, detection_rate: 20.86, hit_rate: 4.21,  num true fraud: 101, num samples: 9120\n",
      "t: 168, suspicious: 1915, fraud in susp: 80, detection_rate: 21.0, hit_rate: 4.18,  num true fraud: 101, num samples: 9120\n",
      "t: 169, suspicious: 1923, fraud in susp: 80, detection_rate: 21.09, hit_rate: 4.16,  num true fraud: 101, num samples: 9120\n",
      "t: 170, suspicious: 1935, fraud in susp: 80, detection_rate: 21.22, hit_rate: 4.13,  num true fraud: 101, num samples: 9120\n",
      "t: 171, suspicious: 1943, fraud in susp: 80, detection_rate: 21.3, hit_rate: 4.12,  num true fraud: 101, num samples: 9120\n",
      "t: 172, suspicious: 1952, fraud in susp: 80, detection_rate: 21.4, hit_rate: 4.1,  num true fraud: 101, num samples: 9120\n",
      "t: 173, suspicious: 1961, fraud in susp: 80, detection_rate: 21.5, hit_rate: 4.08,  num true fraud: 101, num samples: 9120\n",
      "t: 174, suspicious: 1969, fraud in susp: 80, detection_rate: 21.59, hit_rate: 4.06,  num true fraud: 101, num samples: 9120\n",
      "t: 175, suspicious: 1977, fraud in susp: 80, detection_rate: 21.68, hit_rate: 4.05,  num true fraud: 101, num samples: 9120\n",
      "t: 176, suspicious: 1988, fraud in susp: 80, detection_rate: 21.8, hit_rate: 4.02,  num true fraud: 101, num samples: 9120\n",
      "t: 177, suspicious: 2001, fraud in susp: 80, detection_rate: 21.94, hit_rate: 4.0,  num true fraud: 101, num samples: 9120\n",
      "t: 178, suspicious: 2014, fraud in susp: 80, detection_rate: 22.08, hit_rate: 3.97,  num true fraud: 101, num samples: 9120\n",
      "t: 179, suspicious: 2031, fraud in susp: 80, detection_rate: 22.27, hit_rate: 3.94,  num true fraud: 101, num samples: 9120\n",
      "t: 180, suspicious: 2045, fraud in susp: 80, detection_rate: 22.42, hit_rate: 3.91,  num true fraud: 101, num samples: 9120\n",
      "t: 181, suspicious: 2053, fraud in susp: 80, detection_rate: 22.51, hit_rate: 3.9,  num true fraud: 101, num samples: 9120\n",
      "t: 182, suspicious: 2060, fraud in susp: 80, detection_rate: 22.59, hit_rate: 3.88,  num true fraud: 101, num samples: 9120\n",
      "t: 183, suspicious: 2067, fraud in susp: 80, detection_rate: 22.66, hit_rate: 3.87,  num true fraud: 101, num samples: 9120\n",
      "t: 184, suspicious: 2077, fraud in susp: 80, detection_rate: 22.77, hit_rate: 3.85,  num true fraud: 101, num samples: 9120\n",
      "t: 185, suspicious: 2091, fraud in susp: 80, detection_rate: 22.93, hit_rate: 3.83,  num true fraud: 101, num samples: 9120\n",
      "t: 186, suspicious: 2099, fraud in susp: 80, detection_rate: 23.02, hit_rate: 3.81,  num true fraud: 101, num samples: 9120\n",
      "t: 187, suspicious: 2107, fraud in susp: 80, detection_rate: 23.1, hit_rate: 3.8,  num true fraud: 101, num samples: 9120\n",
      "t: 188, suspicious: 2123, fraud in susp: 80, detection_rate: 23.28, hit_rate: 3.77,  num true fraud: 101, num samples: 9120\n",
      "t: 189, suspicious: 2135, fraud in susp: 80, detection_rate: 23.41, hit_rate: 3.75,  num true fraud: 101, num samples: 9120\n",
      "t: 190, suspicious: 2145, fraud in susp: 80, detection_rate: 23.52, hit_rate: 3.73,  num true fraud: 101, num samples: 9120\n",
      "t: 191, suspicious: 2153, fraud in susp: 80, detection_rate: 23.61, hit_rate: 3.72,  num true fraud: 101, num samples: 9120\n",
      "t: 192, suspicious: 2160, fraud in susp: 80, detection_rate: 23.68, hit_rate: 3.7,  num true fraud: 101, num samples: 9120\n",
      "t: 193, suspicious: 2168, fraud in susp: 80, detection_rate: 23.77, hit_rate: 3.69,  num true fraud: 101, num samples: 9120\n",
      "t: 194, suspicious: 2174, fraud in susp: 80, detection_rate: 23.84, hit_rate: 3.68,  num true fraud: 101, num samples: 9120\n",
      "t: 195, suspicious: 2181, fraud in susp: 80, detection_rate: 23.91, hit_rate: 3.67,  num true fraud: 101, num samples: 9120\n",
      "t: 196, suspicious: 2193, fraud in susp: 80, detection_rate: 24.05, hit_rate: 3.65,  num true fraud: 101, num samples: 9120\n",
      "t: 197, suspicious: 2205, fraud in susp: 80, detection_rate: 24.18, hit_rate: 3.63,  num true fraud: 101, num samples: 9120\n",
      "t: 198, suspicious: 2218, fraud in susp: 80, detection_rate: 24.32, hit_rate: 3.61,  num true fraud: 101, num samples: 9120\n",
      "t: 199, suspicious: 2229, fraud in susp: 80, detection_rate: 24.44, hit_rate: 3.59,  num true fraud: 101, num samples: 9120\n"
     ]
    }
   ],
   "source": [
    "def detect_fraud_model_1(t, df):\n",
    "    d = []\n",
    "    h = []\n",
    "\n",
    "    for i in t:\n",
    "        a = 0\n",
    "        b = 0\n",
    "        for j in range(len(df)):\n",
    "            if df[\"Days\"][j] <= i:\n",
    "                a = a + 1\n",
    "                if df[\"Fraud\"][j] == 1:\n",
    "                    \n",
    "                    b = b + 1\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        detection_rate = round((a / len(df))*100, 2)\n",
    "        d.append(detection_rate)\n",
    "        hit_rate = round((b / a)*100, 2)\n",
    "        h.append(hit_rate)\n",
    "\n",
    "        print(\"t: {}, suspicious: {}, fraud in susp: {},\".format(i, a, b),\n",
    "              \"detection_rate: {}, hit_rate: {}, \".format(detection_rate, hit_rate),\n",
    "              \"num true fraud: {}, num samples: {}\".format(len(df_fraud), len(df)))\n",
    "\n",
    "    return d, h\n",
    "\n",
    "d, h = detect_fraud_model_1(range(200), df_insurance_claims_t_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Hit Rate')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (15, 5))\n",
    "AX1 = fig.add_subplot(1,2,1)\n",
    "AX2 = fig.add_subplot(1,2,2)\n",
    "t = range(200)\n",
    "\n",
    "AX1.plot(t, d, ls = \"--\", color = \"blue\")\n",
    "AX2.plot(t, h, ls = \"--\", color = \"red\")\n",
    "\n",
    "AX1.set_title(\"The Detection Rate Based on different t Days\", fontsize = 15, horizontalalignment=\"center\")\n",
    "AX2.set_title(\"The Hit Rate Based on different t Days\", fontsize = 15, horizontalalignment=\"center\")\n",
    "\n",
    "AX1.set_xlabel(\"Days\", fontsize = 10)\n",
    "AX1.set_ylabel(\"Detection Rate\", fontsize = 10)\n",
    "\n",
    "AX2.set_xlabel(\"Days\", fontsize = 10)\n",
    "AX2.set_ylabel(\"Hit Rate\", fontsize = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: 0, d: 0.33, h: 36.67\n",
      "t: 1, d: 0.59, h: 27.78\n",
      "t: 2, d: 0.79, h: 31.94\n",
      "t: 3, d: 0.94, h: 29.07\n",
      "t: 4, d: 1.32, h: 25.83\n",
      "t: 5, d: 1.59, h: 24.14\n",
      "t: 6, d: 1.88, h: 24.56\n",
      "t: 7, d: 2.12, h: 22.8\n",
      "t: 8, d: 2.34, h: 21.6\n",
      "t: 9, d: 2.48, h: 21.24\n",
      "t: 10, d: 2.58, h: 21.28\n",
      "t: 11, d: 2.73, h: 20.88\n",
      "t: 12, d: 2.97, h: 19.19\n",
      "t: 13, d: 3.08, h: 18.51\n",
      "t: 14, d: 3.28, h: 18.73\n",
      "t: 15, d: 3.43, h: 17.89\n",
      "t: 16, d: 3.59, h: 17.74\n",
      "t: 17, d: 3.8, h: 17.58\n",
      "t: 18, d: 3.97, h: 17.4\n",
      "t: 19, d: 4.07, h: 17.25\n",
      "t: 20, d: 4.3, h: 16.58\n",
      "t: 21, d: 4.44, h: 16.05\n",
      "t: 22, d: 4.58, h: 16.03\n",
      "t: 23, d: 4.75, h: 15.94\n",
      "t: 24, d: 4.87, h: 15.99\n",
      "t: 25, d: 5.02, h: 15.72\n",
      "t: 26, d: 5.18, h: 15.47\n",
      "t: 27, d: 5.27, h: 15.18\n",
      "t: 28, d: 5.44, h: 15.12\n",
      "t: 29, d: 5.64, h: 14.98\n",
      "t: 30, d: 5.84, h: 14.45\n",
      "t: 31, d: 5.99, h: 14.1\n",
      "t: 32, d: 6.1, h: 13.85\n",
      "t: 33, d: 6.22, h: 13.58\n",
      "t: 34, d: 6.32, h: 13.37\n",
      "t: 35, d: 6.41, h: 13.16\n",
      "t: 36, d: 6.51, h: 12.96\n",
      "t: 37, d: 6.66, h: 12.69\n",
      "t: 38, d: 6.75, h: 12.5\n",
      "t: 39, d: 6.9, h: 12.24\n",
      "t: 40, d: 7.06, h: 11.96\n",
      "t: 41, d: 7.17, h: 11.77\n",
      "t: 42, d: 7.24, h: 11.67\n",
      "t: 43, d: 7.32, h: 11.53\n",
      "t: 44, d: 7.47, h: 11.31\n",
      "t: 45, d: 7.59, h: 11.13\n",
      "t: 46, d: 7.73, h: 10.92\n",
      "t: 47, d: 7.86, h: 10.88\n",
      "t: 48, d: 7.95, h: 10.76\n",
      "t: 49, d: 8.11, h: 10.54\n",
      "t: 50, d: 8.22, h: 10.4\n",
      "t: 51, d: 8.36, h: 10.24\n",
      "t: 52, d: 8.49, h: 10.08\n",
      "t: 53, d: 8.57, h: 9.97\n",
      "t: 54, d: 8.67, h: 9.86\n",
      "t: 55, d: 8.77, h: 9.75\n",
      "t: 56, d: 8.85, h: 9.67\n",
      "t: 57, d: 9.05, h: 9.45\n",
      "t: 58, d: 9.17, h: 9.33\n",
      "t: 59, d: 9.31, h: 9.19\n",
      "t: 60, d: 9.45, h: 9.05\n",
      "t: 61, d: 9.54, h: 8.97\n",
      "t: 62, d: 9.59, h: 8.91\n",
      "t: 63, d: 9.75, h: 8.77\n",
      "t: 64, d: 9.87, h: 8.67\n",
      "t: 65, d: 10.04, h: 8.52\n",
      "t: 66, d: 10.18, h: 8.41\n",
      "t: 67, d: 10.32, h: 8.29\n",
      "t: 68, d: 10.43, h: 8.2\n",
      "t: 69, d: 10.5, h: 8.14\n",
      "t: 70, d: 10.6, h: 8.17\n",
      "t: 71, d: 10.75, h: 8.16\n",
      "t: 72, d: 10.86, h: 8.08\n",
      "t: 73, d: 10.98, h: 7.99\n",
      "t: 74, d: 11.1, h: 7.91\n",
      "t: 75, d: 11.22, h: 7.82\n",
      "t: 76, d: 11.35, h: 7.73\n",
      "t: 77, d: 11.49, h: 7.63\n",
      "t: 78, d: 11.57, h: 7.58\n",
      "t: 79, d: 11.71, h: 7.49\n",
      "t: 80, d: 11.78, h: 7.45\n",
      "t: 81, d: 11.89, h: 7.38\n",
      "t: 82, d: 12.0, h: 7.31\n",
      "t: 83, d: 12.13, h: 7.23\n",
      "t: 84, d: 12.2, h: 7.19\n",
      "t: 85, d: 12.29, h: 7.14\n",
      "t: 86, d: 12.41, h: 7.07\n",
      "t: 87, d: 12.53, h: 7.0\n",
      "t: 88, d: 12.64, h: 6.94\n",
      "t: 89, d: 12.77, h: 6.87\n",
      "t: 90, d: 12.91, h: 6.8\n",
      "t: 91, d: 12.99, h: 6.75\n",
      "t: 92, d: 13.09, h: 6.7\n",
      "t: 93, d: 13.2, h: 6.64\n",
      "t: 94, d: 13.37, h: 6.56\n",
      "t: 95, d: 13.51, h: 6.49\n",
      "t: 96, d: 13.57, h: 6.46\n",
      "t: 97, d: 13.64, h: 6.43\n",
      "t: 98, d: 13.76, h: 6.37\n",
      "t: 99, d: 13.85, h: 6.33\n",
      "t: 100, d: 13.95, h: 6.29\n",
      "t: 101, d: 14.05, h: 6.25\n",
      "t: 102, d: 14.14, h: 6.2\n",
      "t: 103, d: 14.24, h: 6.16\n",
      "t: 104, d: 14.32, h: 6.13\n",
      "t: 105, d: 14.44, h: 6.07\n",
      "t: 106, d: 14.61, h: 6.01\n",
      "t: 107, d: 14.69, h: 5.97\n",
      "t: 108, d: 14.77, h: 5.94\n",
      "t: 109, d: 14.88, h: 5.9\n",
      "t: 110, d: 14.98, h: 5.86\n",
      "t: 111, d: 15.07, h: 5.82\n",
      "t: 112, d: 15.15, h: 5.79\n",
      "t: 113, d: 15.23, h: 5.76\n",
      "t: 114, d: 15.36, h: 5.71\n",
      "t: 115, d: 15.45, h: 5.68\n",
      "t: 116, d: 15.49, h: 5.66\n",
      "t: 117, d: 15.6, h: 5.62\n",
      "t: 118, d: 15.72, h: 5.58\n",
      "t: 119, d: 15.77, h: 5.56\n",
      "t: 120, d: 15.84, h: 5.54\n",
      "t: 121, d: 15.88, h: 5.52\n",
      "t: 122, d: 15.98, h: 5.49\n",
      "t: 123, d: 16.09, h: 5.45\n",
      "t: 124, d: 16.18, h: 5.42\n",
      "t: 125, d: 16.3, h: 5.38\n",
      "t: 126, d: 16.45, h: 5.33\n",
      "t: 127, d: 16.56, h: 5.3\n",
      "t: 128, d: 16.71, h: 5.25\n",
      "t: 129, d: 16.84, h: 5.21\n",
      "t: 130, d: 16.93, h: 5.18\n",
      "t: 131, d: 17.07, h: 5.14\n",
      "t: 132, d: 17.19, h: 5.1\n",
      "t: 133, d: 17.3, h: 5.07\n",
      "t: 134, d: 17.36, h: 5.05\n",
      "t: 135, d: 17.46, h: 5.03\n",
      "t: 136, d: 17.6, h: 4.98\n",
      "t: 137, d: 17.62, h: 4.98\n",
      "t: 138, d: 17.69, h: 4.96\n",
      "t: 139, d: 17.77, h: 4.94\n",
      "t: 140, d: 17.89, h: 4.9\n",
      "t: 141, d: 17.97, h: 4.88\n",
      "t: 142, d: 18.04, h: 4.86\n",
      "t: 143, d: 18.15, h: 4.83\n",
      "t: 144, d: 18.2, h: 4.82\n",
      "t: 145, d: 18.31, h: 4.79\n",
      "t: 146, d: 18.43, h: 4.76\n",
      "t: 147, d: 18.56, h: 4.73\n",
      "t: 148, d: 18.68, h: 4.69\n",
      "t: 149, d: 18.78, h: 4.67\n",
      "t: 150, d: 18.91, h: 4.64\n",
      "t: 151, d: 19.04, h: 4.61\n",
      "t: 152, d: 19.11, h: 4.59\n",
      "t: 153, d: 19.23, h: 4.56\n",
      "t: 154, d: 19.32, h: 4.54\n",
      "t: 155, d: 19.42, h: 4.52\n",
      "t: 156, d: 19.56, h: 4.48\n",
      "t: 157, d: 19.66, h: 4.46\n",
      "t: 158, d: 19.73, h: 4.45\n",
      "t: 159, d: 19.84, h: 4.42\n",
      "t: 160, d: 19.93, h: 4.4\n",
      "t: 161, d: 20.1, h: 4.36\n",
      "t: 162, d: 20.2, h: 4.34\n",
      "t: 163, d: 20.36, h: 4.31\n",
      "t: 164, d: 20.47, h: 4.28\n",
      "t: 165, d: 20.59, h: 4.26\n",
      "t: 166, d: 20.75, h: 4.23\n",
      "t: 167, d: 20.86, h: 4.21\n",
      "t: 168, d: 21.0, h: 4.18\n",
      "t: 169, d: 21.09, h: 4.16\n",
      "t: 170, d: 21.22, h: 4.13\n",
      "t: 171, d: 21.3, h: 4.12\n",
      "t: 172, d: 21.4, h: 4.1\n",
      "t: 173, d: 21.5, h: 4.08\n",
      "t: 174, d: 21.59, h: 4.06\n",
      "t: 175, d: 21.68, h: 4.05\n",
      "t: 176, d: 21.8, h: 4.02\n",
      "t: 177, d: 21.94, h: 4.0\n",
      "t: 178, d: 22.08, h: 3.97\n",
      "t: 179, d: 22.27, h: 3.94\n",
      "t: 180, d: 22.42, h: 3.91\n",
      "t: 181, d: 22.51, h: 3.9\n",
      "t: 182, d: 22.59, h: 3.88\n",
      "t: 183, d: 22.66, h: 3.87\n",
      "t: 184, d: 22.77, h: 3.85\n",
      "t: 185, d: 22.93, h: 3.83\n",
      "t: 186, d: 23.02, h: 3.81\n",
      "t: 187, d: 23.1, h: 3.8\n",
      "t: 188, d: 23.28, h: 3.77\n",
      "t: 189, d: 23.41, h: 3.75\n",
      "t: 190, d: 23.52, h: 3.73\n",
      "t: 191, d: 23.61, h: 3.72\n",
      "t: 192, d: 23.68, h: 3.7\n",
      "t: 193, d: 23.77, h: 3.69\n",
      "t: 194, d: 23.84, h: 3.68\n",
      "t: 195, d: 23.91, h: 3.67\n",
      "t: 196, d: 24.05, h: 3.65\n",
      "t: 197, d: 24.18, h: 3.63\n",
      "t: 198, d: 24.32, h: 3.61\n",
      "t: 199, d: 24.44, h: 3.59\n"
     ]
    }
   ],
   "source": [
    "for i in t:\n",
    "    print(\"t: {}, d: {}, h: {}\".format(i, d[i], h[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9120 entries, 0 to 9119\n",
      "Data columns (total 31 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   index                            9120 non-null   int64  \n",
      " 1   PolicyholderOccupation           9120 non-null   object \n",
      " 2   LossDate                         9120 non-null   object \n",
      " 3   FirstPolicySubscriptionDate      9120 non-null   object \n",
      " 4   ClaimCause                       9120 non-null   object \n",
      " 5   FirstPartyVehicleType            9120 non-null   object \n",
      " 6   ConnectionBetweenParties         9120 non-null   object \n",
      " 7   PolicyWasSubscribedOnInternet    9120 non-null   int64  \n",
      " 8   NumberOfPoliciesOfPolicyholder   9120 non-null   int64  \n",
      " 9   FpVehicleAgeMonths               9120 non-null   float64\n",
      " 10  EasinessToStage                  9120 non-null   float64\n",
      " 11  ClaimWihoutIdentifiedThirdParty  9120 non-null   int64  \n",
      " 12  ClaimAmount                      9120 non-null   float64\n",
      " 13  LossHour                         9120 non-null   float64\n",
      " 14  PolicyHolderAge                  9120 non-null   float64\n",
      " 15  NumberOfBodilyInjuries           9120 non-null   int64  \n",
      " 16  FirstPartyLiability              9120 non-null   float64\n",
      " 17  Fraud                            9120 non-null   int64  \n",
      " 18  PolicyHolderCount                9120 non-null   int64  \n",
      " 19  Accessories                      9120 non-null   uint8  \n",
      " 20  ActLiability                     9120 non-null   uint8  \n",
      " 21  Burglary                         9120 non-null   uint8  \n",
      " 22  Fire                             9120 non-null   uint8  \n",
      " 23  MaterialDamages                  9120 non-null   uint8  \n",
      " 24  MedicalCare                      9120 non-null   uint8  \n",
      " 25  NaturalCatastrophes              9120 non-null   uint8  \n",
      " 26  ReplacementVehicle               9120 non-null   uint8  \n",
      " 27  Theft                            9120 non-null   uint8  \n",
      " 28  ThirdParty                       9120 non-null   uint8  \n",
      " 29  ThirdPartyMaterialDamages        9120 non-null   uint8  \n",
      " 30  Windscreen                       9120 non-null   uint8  \n",
      "dtypes: float64(6), int64(7), object(6), uint8(12)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_insurance_claims.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of the cleaned data\n",
    "df_insurance_claims_nn = df_insurance_claims.copy(deep = True)\n",
    "# print(df_insurance_claims_nn.info())\n",
    "\n",
    "# add the days column as before\n",
    "df_insurance_claims_nn[\"LossDate\"] = pd.to_datetime(df_insurance_claims_nn[\"LossDate\"])\n",
    "df_insurance_claims_nn[\"FirstPolicySubscriptionDate\"] = pd.to_datetime(df_insurance_claims_nn[\"FirstPolicySubscriptionDate\"])\n",
    "df_insurance_claims_nn[\"Days\"] = df_insurance_claims_nn[\"LossDate\"] - df_insurance_claims_nn[\"FirstPolicySubscriptionDate\"]\n",
    "df_insurance_claims_nn[\"Days\"] = pd.to_numeric(df_insurance_claims_nn[\"Days\"].dt.days, downcast='integer')\n",
    "df_insurance_claims_nn = df_insurance_claims_nn.astype({\"Days\": \"int64\"})\n",
    "\n",
    "# drop columns that are not required\n",
    "df_insurance_claims_nn.drop(columns=[\"index\", \"LossDate\", \"FirstPolicySubscriptionDate\"], inplace=True)\n",
    "\n",
    "# get the different column types\n",
    "categorical_columns = []\n",
    "binary_columns = [\"Fraud\", \"PolicyWasSubscribedOnInternet\", \"ClaimWithoutIdentifiedThirdParty\"]\n",
    "numerical_columns = []\n",
    "for col in df_insurance_claims_nn.columns:\n",
    "    if df_insurance_claims_nn[col].dtype not in ['int64', \"float64\", \"uint8\"]:\n",
    "        categorical_columns.append(col)\n",
    "    else:\n",
    "        # not binary data and not previously one-hot encoded\n",
    "        if col not in binary_columns and df_insurance_claims_nn[col].dtype != \"uint8\":\n",
    "            numerical_columns.append(col)\n",
    "\n",
    "# one hot encode the categorical columns\n",
    "df_insurance_claims_nn = pd.get_dummies(df_insurance_claims_nn, drop_first=True, columns=categorical_columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the dataset for the autoencoder.\n",
    "- Training data contains only non fraud samples\n",
    "- Validation and test data contain equal number of fraud and non fraud data samples. These are picked randomly from the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of fraud data:  101\n",
      "Amount of non-fraud data:  9019\n",
      "(902, 59)\n",
      "(902,)\n",
      "(1003, 59)\n",
      "(1003,)\n"
     ]
    }
   ],
   "source": [
    "# separate the fraud and non-fraud samples\n",
    "df_fraud_data = df_insurance_claims_nn[df_insurance_claims_nn[\"Fraud\"] == 1]\n",
    "df_non_fraud_data = df_insurance_claims_nn[df_insurance_claims_nn[\"Fraud\"] == 0]\n",
    "\n",
    "# separate the Fraud column from the rest of the features\n",
    "x_fraud_data = df_fraud_data.drop(columns=[\"Fraud\"])\n",
    "y_fraud_data = df_fraud_data[\"Fraud\"]\n",
    "x_non_fraud_data = df_non_fraud_data.drop(columns=[\"Fraud\"])\n",
    "y_non_fraud_data = df_non_fraud_data[\"Fraud\"]\n",
    "\n",
    "print(\"Amount of fraud data: \", len(df_fraud_data))\n",
    "print(\"Amount of non-fraud data: \", len(df_non_fraud_data))\n",
    "\n",
    "# Create training set with only non-fraud data\n",
    "# first separate out non-fraud data equal to the amount of fraud data\n",
    "x_train, x_other, y_train, y_other = train_test_split(x_non_fraud_data, y_non_fraud_data, train_size=0.9, shuffle=True, random_state=98)\n",
    "\n",
    "print(x_other.shape)\n",
    "print(y_other.shape)\n",
    "\n",
    "# Concatenate the remaining data with the fraud data\n",
    "x_other = pd.concat((x_other, x_fraud_data), axis=0)\n",
    "y_other = pd.concat((y_other, y_fraud_data), axis=0)\n",
    "\n",
    "print(x_other.shape)\n",
    "print(y_other.shape)\n",
    "\n",
    "# split this data in half with statify set to y_other to get the validation and test data\n",
    "x_valid, x_test, y_valid, y_test = train_test_split(x_other, y_other, train_size=0.5, stratify=y_other, shuffle=True, random_state=28)\n",
    "\n",
    "# apply standard scaler to the data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_train[numerical_columns])\n",
    "x_train[numerical_columns] = scaler.transform(x_train[numerical_columns])\n",
    "x_valid[numerical_columns] = scaler.transform(x_valid[numerical_columns])\n",
    "x_test[numerical_columns] = scaler.transform(x_test[numerical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fraud_data[\"Fraud\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (8117, 59)\n",
      "valid: (501, 59)\n",
      "test: (502, 59)\n"
     ]
    }
   ],
   "source": [
    "print(\"train: {}\".format(x_train.shape))\n",
    "print(\"valid: {}\".format(x_valid.shape))\n",
    "print(\"test: {}\".format(x_test.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Build the network architecture - basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Encoder - 16 neurons in first layer, 8 neurons in second layer\n",
    "encoder = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(x_train.shape[1], )),\n",
    "    tf.keras.layers.Dense(32, activation=\"elu\"),\n",
    "    tf.keras.layers.Dense(16, activation=\"relu\"), \n",
    "    tf.keras.layers.Dense(8, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(4, activation=\"relu\")\n",
    "    ], \n",
    "    name='encoder')\n",
    "\n",
    "# Decoder - 8 neurons in first layer, 16 neurons in second layer, 57 neurons in output layer\n",
    "decoder = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(8, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(x_train.shape[1], activation=\"sigmoid\")], \n",
    "    name='decoder')\n",
    "\n",
    "autoencoder = tf.keras.Sequential([encoder, decoder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                1920      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,584\n",
      "Trainable params: 2,584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.build(x_train.shape)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (8117, 16)                144       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (8117, 32)                544       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (8117, 59)                1947      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,635\n",
      "Trainable params: 2,635\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder (Sequential)        (None, 8)                 2584      \n",
      "                                                                 \n",
      " decoder (Sequential)        (8117, 59)                2635      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,219\n",
      "Trainable params: 5,219\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "26/26 [==============================] - 2s 14ms/step - loss: 0.2277 - mean_squared_error: 0.2277 - accuracy: 0.1780 - val_loss: 0.2105 - val_mean_squared_error: 0.2105 - val_accuracy: 0.1823\n",
      "Epoch 2/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.1619 - mean_squared_error: 0.1619 - accuracy: 0.1884 - val_loss: 0.0926 - val_mean_squared_error: 0.0926 - val_accuracy: 0.1823\n",
      "Epoch 3/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0686 - mean_squared_error: 0.0686 - accuracy: 0.1884 - val_loss: 0.0580 - val_mean_squared_error: 0.0580 - val_accuracy: 0.1823\n",
      "Epoch 4/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0556 - mean_squared_error: 0.0556 - accuracy: 0.2521 - val_loss: 0.0545 - val_mean_squared_error: 0.0545 - val_accuracy: 0.4070\n",
      "Epoch 5/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0543 - mean_squared_error: 0.0543 - accuracy: 0.3920 - val_loss: 0.0540 - val_mean_squared_error: 0.0540 - val_accuracy: 0.4070\n",
      "Epoch 6/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0541 - mean_squared_error: 0.0541 - accuracy: 0.3920 - val_loss: 0.0539 - val_mean_squared_error: 0.0539 - val_accuracy: 0.4070\n",
      "Epoch 7/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0539 - mean_squared_error: 0.0539 - accuracy: 0.3920 - val_loss: 0.0537 - val_mean_squared_error: 0.0537 - val_accuracy: 0.4070\n",
      "Epoch 8/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0538 - mean_squared_error: 0.0538 - accuracy: 0.3920 - val_loss: 0.0536 - val_mean_squared_error: 0.0536 - val_accuracy: 0.4070\n",
      "Epoch 9/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0537 - mean_squared_error: 0.0537 - accuracy: 0.3784 - val_loss: 0.0535 - val_mean_squared_error: 0.0535 - val_accuracy: 0.4070\n",
      "Epoch 10/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0536 - mean_squared_error: 0.0536 - accuracy: 0.3920 - val_loss: 0.0534 - val_mean_squared_error: 0.0534 - val_accuracy: 0.4070\n",
      "Epoch 11/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0535 - mean_squared_error: 0.0535 - accuracy: 0.3920 - val_loss: 0.0534 - val_mean_squared_error: 0.0534 - val_accuracy: 0.4070\n",
      "Epoch 12/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0534 - mean_squared_error: 0.0534 - accuracy: 0.3920 - val_loss: 0.0533 - val_mean_squared_error: 0.0533 - val_accuracy: 0.4070\n",
      "Epoch 13/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0533 - mean_squared_error: 0.0533 - accuracy: 0.3182 - val_loss: 0.0532 - val_mean_squared_error: 0.0532 - val_accuracy: 0.4070\n",
      "Epoch 14/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0533 - mean_squared_error: 0.0533 - accuracy: 0.3920 - val_loss: 0.0531 - val_mean_squared_error: 0.0531 - val_accuracy: 0.4070\n",
      "Epoch 15/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0532 - mean_squared_error: 0.0532 - accuracy: 0.3920 - val_loss: 0.0530 - val_mean_squared_error: 0.0530 - val_accuracy: 0.4070\n",
      "Epoch 16/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0531 - mean_squared_error: 0.0531 - accuracy: 0.3920 - val_loss: 0.0530 - val_mean_squared_error: 0.0530 - val_accuracy: 0.4070\n",
      "Epoch 17/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0530 - mean_squared_error: 0.0530 - accuracy: 0.3920 - val_loss: 0.0529 - val_mean_squared_error: 0.0529 - val_accuracy: 0.4070\n",
      "Epoch 18/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0529 - mean_squared_error: 0.0529 - accuracy: 0.3920 - val_loss: 0.0529 - val_mean_squared_error: 0.0529 - val_accuracy: 0.4070\n",
      "Epoch 19/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0528 - mean_squared_error: 0.0528 - accuracy: 0.3920 - val_loss: 0.0527 - val_mean_squared_error: 0.0527 - val_accuracy: 0.4070\n",
      "Epoch 20/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0528 - mean_squared_error: 0.0528 - accuracy: 0.3920 - val_loss: 0.0526 - val_mean_squared_error: 0.0526 - val_accuracy: 0.4070\n",
      "Epoch 21/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0526 - mean_squared_error: 0.0526 - accuracy: 0.3920 - val_loss: 0.0525 - val_mean_squared_error: 0.0525 - val_accuracy: 0.4070\n",
      "Epoch 22/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0526 - mean_squared_error: 0.0526 - accuracy: 0.3649 - val_loss: 0.0526 - val_mean_squared_error: 0.0526 - val_accuracy: 0.1872\n",
      "Epoch 23/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0525 - mean_squared_error: 0.0525 - accuracy: 0.3686 - val_loss: 0.0524 - val_mean_squared_error: 0.0524 - val_accuracy: 0.3645\n",
      "Epoch 24/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0523 - mean_squared_error: 0.0523 - accuracy: 0.3796 - val_loss: 0.0522 - val_mean_squared_error: 0.0522 - val_accuracy: 0.4070\n",
      "Epoch 25/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0522 - mean_squared_error: 0.0522 - accuracy: 0.3920 - val_loss: 0.0521 - val_mean_squared_error: 0.0521 - val_accuracy: 0.3664\n",
      "Epoch 26/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0521 - mean_squared_error: 0.0521 - accuracy: 0.3861 - val_loss: 0.0520 - val_mean_squared_error: 0.0520 - val_accuracy: 0.4070\n",
      "Epoch 27/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0519 - mean_squared_error: 0.0519 - accuracy: 0.3889 - val_loss: 0.0516 - val_mean_squared_error: 0.0516 - val_accuracy: 0.4871\n",
      "Epoch 28/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0512 - mean_squared_error: 0.0512 - accuracy: 0.4285 - val_loss: 0.0505 - val_mean_squared_error: 0.0505 - val_accuracy: 0.4594\n",
      "Epoch 29/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0490 - mean_squared_error: 0.0490 - accuracy: 0.4824 - val_loss: 0.0456 - val_mean_squared_error: 0.0456 - val_accuracy: 0.4612\n",
      "Epoch 30/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0410 - mean_squared_error: 0.0410 - accuracy: 0.2416 - val_loss: 0.0358 - val_mean_squared_error: 0.0358 - val_accuracy: 0.2044\n",
      "Epoch 31/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0350 - mean_squared_error: 0.0350 - accuracy: 0.1948 - val_loss: 0.0332 - val_mean_squared_error: 0.0332 - val_accuracy: 0.1841\n",
      "Epoch 32/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0333 - mean_squared_error: 0.0333 - accuracy: 0.1917 - val_loss: 0.0320 - val_mean_squared_error: 0.0320 - val_accuracy: 0.1841\n",
      "Epoch 33/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0324 - mean_squared_error: 0.0324 - accuracy: 0.1919 - val_loss: 0.0315 - val_mean_squared_error: 0.0315 - val_accuracy: 0.1853\n",
      "Epoch 34/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0318 - mean_squared_error: 0.0318 - accuracy: 0.1927 - val_loss: 0.0310 - val_mean_squared_error: 0.0310 - val_accuracy: 0.1860\n",
      "Epoch 35/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0314 - mean_squared_error: 0.0314 - accuracy: 0.1927 - val_loss: 0.0307 - val_mean_squared_error: 0.0307 - val_accuracy: 0.1847\n",
      "Epoch 36/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0310 - mean_squared_error: 0.0310 - accuracy: 0.1939 - val_loss: 0.0304 - val_mean_squared_error: 0.0304 - val_accuracy: 0.1872\n",
      "Epoch 37/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0307 - mean_squared_error: 0.0307 - accuracy: 0.1951 - val_loss: 0.0299 - val_mean_squared_error: 0.0299 - val_accuracy: 0.1897\n",
      "Epoch 38/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0303 - mean_squared_error: 0.0303 - accuracy: 0.1999 - val_loss: 0.0295 - val_mean_squared_error: 0.0295 - val_accuracy: 0.1921\n",
      "Epoch 39/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0299 - mean_squared_error: 0.0299 - accuracy: 0.2021 - val_loss: 0.0291 - val_mean_squared_error: 0.0291 - val_accuracy: 0.1933\n",
      "Epoch 40/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0295 - mean_squared_error: 0.0295 - accuracy: 0.2036 - val_loss: 0.0288 - val_mean_squared_error: 0.0288 - val_accuracy: 0.1933\n",
      "Epoch 41/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0292 - mean_squared_error: 0.0292 - accuracy: 0.2045 - val_loss: 0.0284 - val_mean_squared_error: 0.0284 - val_accuracy: 0.1989\n",
      "Epoch 42/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0289 - mean_squared_error: 0.0289 - accuracy: 0.2067 - val_loss: 0.0281 - val_mean_squared_error: 0.0281 - val_accuracy: 0.1964\n",
      "Epoch 43/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0286 - mean_squared_error: 0.0286 - accuracy: 0.2082 - val_loss: 0.0278 - val_mean_squared_error: 0.0278 - val_accuracy: 0.1989\n",
      "Epoch 44/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0284 - mean_squared_error: 0.0284 - accuracy: 0.2085 - val_loss: 0.0276 - val_mean_squared_error: 0.0276 - val_accuracy: 0.1989\n",
      "Epoch 45/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0282 - mean_squared_error: 0.0282 - accuracy: 0.2104 - val_loss: 0.0275 - val_mean_squared_error: 0.0275 - val_accuracy: 0.1989\n",
      "Epoch 46/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0280 - mean_squared_error: 0.0280 - accuracy: 0.2101 - val_loss: 0.0272 - val_mean_squared_error: 0.0272 - val_accuracy: 0.1989\n",
      "Epoch 47/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0277 - mean_squared_error: 0.0277 - accuracy: 0.2105 - val_loss: 0.0270 - val_mean_squared_error: 0.0270 - val_accuracy: 0.1989\n",
      "Epoch 48/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0275 - mean_squared_error: 0.0275 - accuracy: 0.2110 - val_loss: 0.0267 - val_mean_squared_error: 0.0267 - val_accuracy: 0.2007\n",
      "Epoch 49/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0273 - mean_squared_error: 0.0273 - accuracy: 0.2101 - val_loss: 0.0265 - val_mean_squared_error: 0.0265 - val_accuracy: 0.2001\n",
      "Epoch 50/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0271 - mean_squared_error: 0.0271 - accuracy: 0.2142 - val_loss: 0.0263 - val_mean_squared_error: 0.0263 - val_accuracy: 0.2001\n",
      "Epoch 51/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0267 - mean_squared_error: 0.0267 - accuracy: 0.2104 - val_loss: 0.0258 - val_mean_squared_error: 0.0258 - val_accuracy: 0.1983\n",
      "Epoch 52/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0263 - mean_squared_error: 0.0263 - accuracy: 0.2113 - val_loss: 0.0255 - val_mean_squared_error: 0.0255 - val_accuracy: 0.1983\n",
      "Epoch 53/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0260 - mean_squared_error: 0.0260 - accuracy: 0.1916 - val_loss: 0.0251 - val_mean_squared_error: 0.0251 - val_accuracy: 0.1755\n",
      "Epoch 54/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0256 - mean_squared_error: 0.0256 - accuracy: 0.1699 - val_loss: 0.0248 - val_mean_squared_error: 0.0248 - val_accuracy: 0.1459\n",
      "Epoch 55/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0253 - mean_squared_error: 0.0253 - accuracy: 0.1543 - val_loss: 0.0246 - val_mean_squared_error: 0.0246 - val_accuracy: 0.1429\n",
      "Epoch 56/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0251 - mean_squared_error: 0.0251 - accuracy: 0.1341 - val_loss: 0.0242 - val_mean_squared_error: 0.0242 - val_accuracy: 0.1127\n",
      "Epoch 57/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0247 - mean_squared_error: 0.0247 - accuracy: 0.1201 - val_loss: 0.0239 - val_mean_squared_error: 0.0239 - val_accuracy: 0.1022\n",
      "Epoch 58/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0244 - mean_squared_error: 0.0244 - accuracy: 0.1220 - val_loss: 0.0235 - val_mean_squared_error: 0.0235 - val_accuracy: 0.1127\n",
      "Epoch 59/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0239 - mean_squared_error: 0.0239 - accuracy: 0.1204 - val_loss: 0.0230 - val_mean_squared_error: 0.0230 - val_accuracy: 0.1096\n",
      "Epoch 60/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0234 - mean_squared_error: 0.0234 - accuracy: 0.1263 - val_loss: 0.0226 - val_mean_squared_error: 0.0226 - val_accuracy: 0.1139\n",
      "Epoch 61/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0231 - mean_squared_error: 0.0231 - accuracy: 0.1264 - val_loss: 0.0224 - val_mean_squared_error: 0.0224 - val_accuracy: 0.1145\n",
      "Epoch 62/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0228 - mean_squared_error: 0.0228 - accuracy: 0.1288 - val_loss: 0.0221 - val_mean_squared_error: 0.0221 - val_accuracy: 0.1244\n",
      "Epoch 63/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0225 - mean_squared_error: 0.0225 - accuracy: 0.1354 - val_loss: 0.0217 - val_mean_squared_error: 0.0217 - val_accuracy: 0.1373\n",
      "Epoch 64/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0220 - mean_squared_error: 0.0220 - accuracy: 0.1442 - val_loss: 0.0212 - val_mean_squared_error: 0.0212 - val_accuracy: 0.1398\n",
      "Epoch 65/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0215 - mean_squared_error: 0.0215 - accuracy: 0.1508 - val_loss: 0.0208 - val_mean_squared_error: 0.0208 - val_accuracy: 0.1349\n",
      "Epoch 66/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0213 - mean_squared_error: 0.0213 - accuracy: 0.1585 - val_loss: 0.0207 - val_mean_squared_error: 0.0207 - val_accuracy: 0.2014\n",
      "Epoch 67/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0210 - mean_squared_error: 0.0210 - accuracy: 0.1944 - val_loss: 0.0202 - val_mean_squared_error: 0.0202 - val_accuracy: 0.2371\n",
      "Epoch 68/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0207 - mean_squared_error: 0.0207 - accuracy: 0.2309 - val_loss: 0.0200 - val_mean_squared_error: 0.0200 - val_accuracy: 0.2635\n",
      "Epoch 69/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0203 - mean_squared_error: 0.0203 - accuracy: 0.2631 - val_loss: 0.0197 - val_mean_squared_error: 0.0197 - val_accuracy: 0.2666\n",
      "Epoch 70/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0201 - mean_squared_error: 0.0201 - accuracy: 0.2654 - val_loss: 0.0193 - val_mean_squared_error: 0.0193 - val_accuracy: 0.2716\n",
      "Epoch 71/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0197 - mean_squared_error: 0.0197 - accuracy: 0.2689 - val_loss: 0.0190 - val_mean_squared_error: 0.0190 - val_accuracy: 0.2709\n",
      "Epoch 72/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0195 - mean_squared_error: 0.0195 - accuracy: 0.2735 - val_loss: 0.0188 - val_mean_squared_error: 0.0188 - val_accuracy: 0.2796\n",
      "Epoch 73/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0192 - mean_squared_error: 0.0192 - accuracy: 0.2744 - val_loss: 0.0186 - val_mean_squared_error: 0.0186 - val_accuracy: 0.2746\n",
      "Epoch 74/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0189 - mean_squared_error: 0.0189 - accuracy: 0.2771 - val_loss: 0.0182 - val_mean_squared_error: 0.0182 - val_accuracy: 0.2789\n",
      "Epoch 75/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0187 - mean_squared_error: 0.0187 - accuracy: 0.2778 - val_loss: 0.0179 - val_mean_squared_error: 0.0179 - val_accuracy: 0.2796\n",
      "Epoch 76/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0184 - mean_squared_error: 0.0184 - accuracy: 0.2791 - val_loss: 0.0177 - val_mean_squared_error: 0.0177 - val_accuracy: 0.2796\n",
      "Epoch 77/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0183 - mean_squared_error: 0.0183 - accuracy: 0.2809 - val_loss: 0.0176 - val_mean_squared_error: 0.0176 - val_accuracy: 0.2802\n",
      "Epoch 78/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0182 - mean_squared_error: 0.0182 - accuracy: 0.2789 - val_loss: 0.0175 - val_mean_squared_error: 0.0175 - val_accuracy: 0.2802\n",
      "Epoch 79/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0181 - mean_squared_error: 0.0181 - accuracy: 0.2811 - val_loss: 0.0177 - val_mean_squared_error: 0.0177 - val_accuracy: 0.2820\n",
      "Epoch 80/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0181 - mean_squared_error: 0.0181 - accuracy: 0.2828 - val_loss: 0.0173 - val_mean_squared_error: 0.0173 - val_accuracy: 0.2796\n",
      "Epoch 81/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0180 - mean_squared_error: 0.0180 - accuracy: 0.2849 - val_loss: 0.0174 - val_mean_squared_error: 0.0174 - val_accuracy: 0.2783\n",
      "Epoch 82/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0179 - mean_squared_error: 0.0179 - accuracy: 0.2926 - val_loss: 0.0172 - val_mean_squared_error: 0.0172 - val_accuracy: 0.2833\n",
      "Epoch 83/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0177 - mean_squared_error: 0.0177 - accuracy: 0.2940 - val_loss: 0.0171 - val_mean_squared_error: 0.0171 - val_accuracy: 0.2913\n",
      "Epoch 84/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0177 - mean_squared_error: 0.0177 - accuracy: 0.2991 - val_loss: 0.0171 - val_mean_squared_error: 0.0171 - val_accuracy: 0.2980\n",
      "Epoch 85/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0177 - mean_squared_error: 0.0177 - accuracy: 0.3028 - val_loss: 0.0170 - val_mean_squared_error: 0.0170 - val_accuracy: 0.3060\n",
      "Epoch 86/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0175 - mean_squared_error: 0.0175 - accuracy: 0.3099 - val_loss: 0.0170 - val_mean_squared_error: 0.0170 - val_accuracy: 0.3005\n",
      "Epoch 87/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0175 - mean_squared_error: 0.0175 - accuracy: 0.3113 - val_loss: 0.0170 - val_mean_squared_error: 0.0170 - val_accuracy: 0.3251\n",
      "Epoch 88/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0175 - mean_squared_error: 0.0175 - accuracy: 0.3173 - val_loss: 0.0169 - val_mean_squared_error: 0.0169 - val_accuracy: 0.3214\n",
      "Epoch 89/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0174 - mean_squared_error: 0.0174 - accuracy: 0.3165 - val_loss: 0.0166 - val_mean_squared_error: 0.0166 - val_accuracy: 0.3171\n",
      "Epoch 90/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0174 - mean_squared_error: 0.0174 - accuracy: 0.3188 - val_loss: 0.0168 - val_mean_squared_error: 0.0168 - val_accuracy: 0.3300\n",
      "Epoch 91/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0173 - mean_squared_error: 0.0173 - accuracy: 0.3197 - val_loss: 0.0166 - val_mean_squared_error: 0.0166 - val_accuracy: 0.3239\n",
      "Epoch 92/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0172 - mean_squared_error: 0.0172 - accuracy: 0.3208 - val_loss: 0.0165 - val_mean_squared_error: 0.0165 - val_accuracy: 0.3294\n",
      "Epoch 93/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0172 - mean_squared_error: 0.0172 - accuracy: 0.3222 - val_loss: 0.0166 - val_mean_squared_error: 0.0166 - val_accuracy: 0.3239\n",
      "Epoch 94/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0171 - mean_squared_error: 0.0171 - accuracy: 0.3219 - val_loss: 0.0164 - val_mean_squared_error: 0.0164 - val_accuracy: 0.3276\n",
      "Epoch 95/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0171 - mean_squared_error: 0.0171 - accuracy: 0.3220 - val_loss: 0.0165 - val_mean_squared_error: 0.0165 - val_accuracy: 0.3227\n",
      "Epoch 96/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0170 - mean_squared_error: 0.0170 - accuracy: 0.3236 - val_loss: 0.0164 - val_mean_squared_error: 0.0164 - val_accuracy: 0.3251\n",
      "Epoch 97/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0169 - mean_squared_error: 0.0169 - accuracy: 0.3205 - val_loss: 0.0163 - val_mean_squared_error: 0.0163 - val_accuracy: 0.3233\n",
      "Epoch 98/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0169 - mean_squared_error: 0.0169 - accuracy: 0.3185 - val_loss: 0.0163 - val_mean_squared_error: 0.0163 - val_accuracy: 0.3208\n",
      "Epoch 99/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0169 - mean_squared_error: 0.0169 - accuracy: 0.3180 - val_loss: 0.0163 - val_mean_squared_error: 0.0163 - val_accuracy: 0.3251\n",
      "Epoch 100/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0168 - mean_squared_error: 0.0168 - accuracy: 0.3187 - val_loss: 0.0162 - val_mean_squared_error: 0.0162 - val_accuracy: 0.3190\n",
      "Epoch 101/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0168 - mean_squared_error: 0.0168 - accuracy: 0.3154 - val_loss: 0.0162 - val_mean_squared_error: 0.0162 - val_accuracy: 0.3153\n",
      "Epoch 102/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0167 - mean_squared_error: 0.0167 - accuracy: 0.3146 - val_loss: 0.0161 - val_mean_squared_error: 0.0161 - val_accuracy: 0.3214\n",
      "Epoch 103/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0166 - mean_squared_error: 0.0166 - accuracy: 0.3134 - val_loss: 0.0161 - val_mean_squared_error: 0.0161 - val_accuracy: 0.3171\n",
      "Epoch 104/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0166 - mean_squared_error: 0.0166 - accuracy: 0.3130 - val_loss: 0.0160 - val_mean_squared_error: 0.0160 - val_accuracy: 0.3177\n",
      "Epoch 105/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0166 - mean_squared_error: 0.0166 - accuracy: 0.3183 - val_loss: 0.0160 - val_mean_squared_error: 0.0160 - val_accuracy: 0.3288\n",
      "Epoch 106/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0165 - mean_squared_error: 0.0165 - accuracy: 0.3170 - val_loss: 0.0160 - val_mean_squared_error: 0.0160 - val_accuracy: 0.3288\n",
      "Epoch 107/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0165 - mean_squared_error: 0.0165 - accuracy: 0.3156 - val_loss: 0.0161 - val_mean_squared_error: 0.0161 - val_accuracy: 0.3288\n",
      "Epoch 108/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0165 - mean_squared_error: 0.0165 - accuracy: 0.3165 - val_loss: 0.0159 - val_mean_squared_error: 0.0159 - val_accuracy: 0.3288\n",
      "Epoch 109/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0164 - mean_squared_error: 0.0164 - accuracy: 0.3210 - val_loss: 0.0159 - val_mean_squared_error: 0.0159 - val_accuracy: 0.3313\n",
      "Epoch 110/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0164 - mean_squared_error: 0.0164 - accuracy: 0.3219 - val_loss: 0.0158 - val_mean_squared_error: 0.0158 - val_accuracy: 0.3257\n",
      "Epoch 111/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0163 - mean_squared_error: 0.0163 - accuracy: 0.3233 - val_loss: 0.0158 - val_mean_squared_error: 0.0158 - val_accuracy: 0.3393\n",
      "Epoch 112/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0162 - mean_squared_error: 0.0162 - accuracy: 0.3237 - val_loss: 0.0157 - val_mean_squared_error: 0.0157 - val_accuracy: 0.3344\n",
      "Epoch 113/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0162 - mean_squared_error: 0.0162 - accuracy: 0.3245 - val_loss: 0.0158 - val_mean_squared_error: 0.0158 - val_accuracy: 0.3325\n",
      "Epoch 114/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0162 - mean_squared_error: 0.0162 - accuracy: 0.3236 - val_loss: 0.0156 - val_mean_squared_error: 0.0156 - val_accuracy: 0.3337\n",
      "Epoch 115/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0162 - mean_squared_error: 0.0162 - accuracy: 0.3247 - val_loss: 0.0157 - val_mean_squared_error: 0.0157 - val_accuracy: 0.3344\n",
      "Epoch 116/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0162 - mean_squared_error: 0.0162 - accuracy: 0.3256 - val_loss: 0.0157 - val_mean_squared_error: 0.0157 - val_accuracy: 0.3319\n",
      "Epoch 117/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0161 - mean_squared_error: 0.0161 - accuracy: 0.3253 - val_loss: 0.0156 - val_mean_squared_error: 0.0156 - val_accuracy: 0.3399\n",
      "Epoch 118/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0160 - mean_squared_error: 0.0160 - accuracy: 0.3254 - val_loss: 0.0155 - val_mean_squared_error: 0.0155 - val_accuracy: 0.3337\n",
      "Epoch 119/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0160 - mean_squared_error: 0.0160 - accuracy: 0.3271 - val_loss: 0.0155 - val_mean_squared_error: 0.0155 - val_accuracy: 0.3381\n",
      "Epoch 120/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0161 - mean_squared_error: 0.0161 - accuracy: 0.3265 - val_loss: 0.0156 - val_mean_squared_error: 0.0156 - val_accuracy: 0.3368\n",
      "Epoch 121/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0160 - mean_squared_error: 0.0160 - accuracy: 0.3277 - val_loss: 0.0155 - val_mean_squared_error: 0.0155 - val_accuracy: 0.3368\n",
      "Epoch 122/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0160 - mean_squared_error: 0.0160 - accuracy: 0.3279 - val_loss: 0.0155 - val_mean_squared_error: 0.0155 - val_accuracy: 0.3387\n",
      "Epoch 123/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0159 - mean_squared_error: 0.0159 - accuracy: 0.3267 - val_loss: 0.0153 - val_mean_squared_error: 0.0153 - val_accuracy: 0.3393\n",
      "Epoch 124/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0159 - mean_squared_error: 0.0159 - accuracy: 0.3282 - val_loss: 0.0153 - val_mean_squared_error: 0.0153 - val_accuracy: 0.3374\n",
      "Epoch 125/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0159 - mean_squared_error: 0.0159 - accuracy: 0.3288 - val_loss: 0.0154 - val_mean_squared_error: 0.0154 - val_accuracy: 0.3387\n",
      "Epoch 126/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0159 - mean_squared_error: 0.0159 - accuracy: 0.3290 - val_loss: 0.0154 - val_mean_squared_error: 0.0154 - val_accuracy: 0.3381\n",
      "Epoch 127/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0159 - mean_squared_error: 0.0159 - accuracy: 0.3265 - val_loss: 0.0154 - val_mean_squared_error: 0.0154 - val_accuracy: 0.3381\n",
      "Epoch 128/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0158 - mean_squared_error: 0.0158 - accuracy: 0.3293 - val_loss: 0.0155 - val_mean_squared_error: 0.0155 - val_accuracy: 0.3393\n",
      "Epoch 129/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0159 - mean_squared_error: 0.0159 - accuracy: 0.3271 - val_loss: 0.0152 - val_mean_squared_error: 0.0152 - val_accuracy: 0.3387\n",
      "Epoch 130/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0158 - mean_squared_error: 0.0158 - accuracy: 0.3262 - val_loss: 0.0152 - val_mean_squared_error: 0.0152 - val_accuracy: 0.3405\n",
      "Epoch 131/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0157 - mean_squared_error: 0.0157 - accuracy: 0.3288 - val_loss: 0.0152 - val_mean_squared_error: 0.0152 - val_accuracy: 0.3405\n",
      "Epoch 132/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0157 - mean_squared_error: 0.0157 - accuracy: 0.3284 - val_loss: 0.0153 - val_mean_squared_error: 0.0153 - val_accuracy: 0.3442\n",
      "Epoch 133/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0157 - mean_squared_error: 0.0157 - accuracy: 0.3273 - val_loss: 0.0152 - val_mean_squared_error: 0.0152 - val_accuracy: 0.3381\n",
      "Epoch 134/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0157 - mean_squared_error: 0.0157 - accuracy: 0.3259 - val_loss: 0.0152 - val_mean_squared_error: 0.0152 - val_accuracy: 0.3411\n",
      "Epoch 135/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0156 - mean_squared_error: 0.0156 - accuracy: 0.3277 - val_loss: 0.0151 - val_mean_squared_error: 0.0151 - val_accuracy: 0.3399\n",
      "Epoch 136/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0156 - mean_squared_error: 0.0156 - accuracy: 0.3285 - val_loss: 0.0151 - val_mean_squared_error: 0.0151 - val_accuracy: 0.3350\n",
      "Epoch 137/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0155 - mean_squared_error: 0.0155 - accuracy: 0.3302 - val_loss: 0.0150 - val_mean_squared_error: 0.0150 - val_accuracy: 0.3387\n",
      "Epoch 138/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0155 - mean_squared_error: 0.0155 - accuracy: 0.3304 - val_loss: 0.0150 - val_mean_squared_error: 0.0150 - val_accuracy: 0.3411\n",
      "Epoch 139/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0156 - mean_squared_error: 0.0156 - accuracy: 0.3317 - val_loss: 0.0150 - val_mean_squared_error: 0.0150 - val_accuracy: 0.3454\n",
      "Epoch 140/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0155 - mean_squared_error: 0.0155 - accuracy: 0.3310 - val_loss: 0.0150 - val_mean_squared_error: 0.0150 - val_accuracy: 0.3374\n",
      "Epoch 141/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0155 - mean_squared_error: 0.0155 - accuracy: 0.3334 - val_loss: 0.0150 - val_mean_squared_error: 0.0150 - val_accuracy: 0.3417\n",
      "Epoch 142/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0155 - mean_squared_error: 0.0155 - accuracy: 0.3311 - val_loss: 0.0149 - val_mean_squared_error: 0.0149 - val_accuracy: 0.3454\n",
      "Epoch 143/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0155 - mean_squared_error: 0.0155 - accuracy: 0.3350 - val_loss: 0.0152 - val_mean_squared_error: 0.0152 - val_accuracy: 0.3399\n",
      "Epoch 144/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0155 - mean_squared_error: 0.0155 - accuracy: 0.3331 - val_loss: 0.0149 - val_mean_squared_error: 0.0149 - val_accuracy: 0.3461\n",
      "Epoch 145/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0154 - mean_squared_error: 0.0154 - accuracy: 0.3359 - val_loss: 0.0148 - val_mean_squared_error: 0.0148 - val_accuracy: 0.3473\n",
      "Epoch 146/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0154 - mean_squared_error: 0.0154 - accuracy: 0.3384 - val_loss: 0.0149 - val_mean_squared_error: 0.0149 - val_accuracy: 0.3448\n",
      "Epoch 147/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0154 - mean_squared_error: 0.0154 - accuracy: 0.3393 - val_loss: 0.0150 - val_mean_squared_error: 0.0150 - val_accuracy: 0.3553\n",
      "Epoch 148/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0154 - mean_squared_error: 0.0154 - accuracy: 0.3393 - val_loss: 0.0149 - val_mean_squared_error: 0.0149 - val_accuracy: 0.3448\n",
      "Epoch 149/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0153 - mean_squared_error: 0.0153 - accuracy: 0.3430 - val_loss: 0.0148 - val_mean_squared_error: 0.0148 - val_accuracy: 0.3553\n",
      "Epoch 150/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0153 - mean_squared_error: 0.0153 - accuracy: 0.3470 - val_loss: 0.0147 - val_mean_squared_error: 0.0147 - val_accuracy: 0.3578\n",
      "Epoch 151/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0153 - mean_squared_error: 0.0153 - accuracy: 0.3438 - val_loss: 0.0148 - val_mean_squared_error: 0.0148 - val_accuracy: 0.3541\n",
      "Epoch 152/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0153 - mean_squared_error: 0.0153 - accuracy: 0.3481 - val_loss: 0.0148 - val_mean_squared_error: 0.0148 - val_accuracy: 0.3565\n",
      "Epoch 153/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0153 - mean_squared_error: 0.0153 - accuracy: 0.3456 - val_loss: 0.0147 - val_mean_squared_error: 0.0147 - val_accuracy: 0.3559\n",
      "Epoch 154/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0153 - mean_squared_error: 0.0153 - accuracy: 0.3441 - val_loss: 0.0147 - val_mean_squared_error: 0.0147 - val_accuracy: 0.3608\n",
      "Epoch 155/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0153 - mean_squared_error: 0.0153 - accuracy: 0.3511 - val_loss: 0.0148 - val_mean_squared_error: 0.0148 - val_accuracy: 0.3590\n",
      "Epoch 156/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0153 - mean_squared_error: 0.0153 - accuracy: 0.3530 - val_loss: 0.0147 - val_mean_squared_error: 0.0147 - val_accuracy: 0.3608\n",
      "Epoch 157/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0152 - mean_squared_error: 0.0152 - accuracy: 0.3505 - val_loss: 0.0147 - val_mean_squared_error: 0.0147 - val_accuracy: 0.3578\n",
      "Epoch 158/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0152 - mean_squared_error: 0.0152 - accuracy: 0.3538 - val_loss: 0.0146 - val_mean_squared_error: 0.0146 - val_accuracy: 0.3639\n",
      "Epoch 159/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0152 - mean_squared_error: 0.0152 - accuracy: 0.3542 - val_loss: 0.0147 - val_mean_squared_error: 0.0147 - val_accuracy: 0.3584\n",
      "Epoch 160/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0152 - mean_squared_error: 0.0152 - accuracy: 0.3558 - val_loss: 0.0147 - val_mean_squared_error: 0.0147 - val_accuracy: 0.3645\n",
      "Epoch 161/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0153 - mean_squared_error: 0.0153 - accuracy: 0.3567 - val_loss: 0.0149 - val_mean_squared_error: 0.0149 - val_accuracy: 0.3633\n",
      "Epoch 162/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0152 - mean_squared_error: 0.0152 - accuracy: 0.3587 - val_loss: 0.0147 - val_mean_squared_error: 0.0147 - val_accuracy: 0.3627\n",
      "Epoch 163/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0152 - mean_squared_error: 0.0152 - accuracy: 0.3570 - val_loss: 0.0147 - val_mean_squared_error: 0.0147 - val_accuracy: 0.3658\n",
      "Epoch 164/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0152 - mean_squared_error: 0.0152 - accuracy: 0.3570 - val_loss: 0.0148 - val_mean_squared_error: 0.0148 - val_accuracy: 0.3651\n",
      "Epoch 165/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0152 - mean_squared_error: 0.0152 - accuracy: 0.3579 - val_loss: 0.0147 - val_mean_squared_error: 0.0147 - val_accuracy: 0.3633\n",
      "Epoch 166/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0152 - mean_squared_error: 0.0152 - accuracy: 0.3581 - val_loss: 0.0147 - val_mean_squared_error: 0.0147 - val_accuracy: 0.3664\n",
      "Epoch 167/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0152 - mean_squared_error: 0.0152 - accuracy: 0.3555 - val_loss: 0.0146 - val_mean_squared_error: 0.0146 - val_accuracy: 0.3670\n",
      "Epoch 168/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0151 - mean_squared_error: 0.0151 - accuracy: 0.3592 - val_loss: 0.0146 - val_mean_squared_error: 0.0146 - val_accuracy: 0.3627\n",
      "Epoch 169/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0151 - mean_squared_error: 0.0151 - accuracy: 0.3601 - val_loss: 0.0147 - val_mean_squared_error: 0.0147 - val_accuracy: 0.3664\n",
      "Epoch 170/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0150 - mean_squared_error: 0.0150 - accuracy: 0.3604 - val_loss: 0.0145 - val_mean_squared_error: 0.0145 - val_accuracy: 0.3670\n",
      "Epoch 171/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0151 - mean_squared_error: 0.0151 - accuracy: 0.3602 - val_loss: 0.0146 - val_mean_squared_error: 0.0146 - val_accuracy: 0.3688\n",
      "Epoch 172/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0151 - mean_squared_error: 0.0151 - accuracy: 0.3618 - val_loss: 0.0146 - val_mean_squared_error: 0.0146 - val_accuracy: 0.3651\n",
      "Epoch 173/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0150 - mean_squared_error: 0.0150 - accuracy: 0.3598 - val_loss: 0.0145 - val_mean_squared_error: 0.0145 - val_accuracy: 0.3670\n",
      "Epoch 174/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0150 - mean_squared_error: 0.0150 - accuracy: 0.3618 - val_loss: 0.0146 - val_mean_squared_error: 0.0146 - val_accuracy: 0.3651\n",
      "Epoch 175/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0151 - mean_squared_error: 0.0151 - accuracy: 0.3621 - val_loss: 0.0147 - val_mean_squared_error: 0.0147 - val_accuracy: 0.3688\n",
      "Epoch 176/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0151 - mean_squared_error: 0.0151 - accuracy: 0.3619 - val_loss: 0.0145 - val_mean_squared_error: 0.0145 - val_accuracy: 0.3676\n",
      "Epoch 177/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0151 - mean_squared_error: 0.0151 - accuracy: 0.3615 - val_loss: 0.0146 - val_mean_squared_error: 0.0146 - val_accuracy: 0.3744\n",
      "Epoch 178/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0150 - mean_squared_error: 0.0150 - accuracy: 0.3653 - val_loss: 0.0145 - val_mean_squared_error: 0.0145 - val_accuracy: 0.3688\n",
      "Epoch 179/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0150 - mean_squared_error: 0.0150 - accuracy: 0.3601 - val_loss: 0.0146 - val_mean_squared_error: 0.0146 - val_accuracy: 0.3651\n",
      "Epoch 180/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0150 - mean_squared_error: 0.0150 - accuracy: 0.3638 - val_loss: 0.0145 - val_mean_squared_error: 0.0145 - val_accuracy: 0.3781\n",
      "Epoch 181/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0150 - mean_squared_error: 0.0150 - accuracy: 0.3698 - val_loss: 0.0146 - val_mean_squared_error: 0.0146 - val_accuracy: 0.3719\n",
      "Epoch 182/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0150 - mean_squared_error: 0.0150 - accuracy: 0.3679 - val_loss: 0.0145 - val_mean_squared_error: 0.0145 - val_accuracy: 0.3768\n",
      "Epoch 183/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0150 - mean_squared_error: 0.0150 - accuracy: 0.3675 - val_loss: 0.0145 - val_mean_squared_error: 0.0145 - val_accuracy: 0.3824\n",
      "Epoch 184/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0150 - mean_squared_error: 0.0150 - accuracy: 0.3716 - val_loss: 0.0144 - val_mean_squared_error: 0.0144 - val_accuracy: 0.3719\n",
      "Epoch 185/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0150 - mean_squared_error: 0.0150 - accuracy: 0.3664 - val_loss: 0.0144 - val_mean_squared_error: 0.0144 - val_accuracy: 0.3738\n",
      "Epoch 186/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0149 - mean_squared_error: 0.0149 - accuracy: 0.3676 - val_loss: 0.0144 - val_mean_squared_error: 0.0144 - val_accuracy: 0.3781\n",
      "Epoch 187/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0150 - mean_squared_error: 0.0150 - accuracy: 0.3698 - val_loss: 0.0145 - val_mean_squared_error: 0.0145 - val_accuracy: 0.3812\n",
      "Epoch 188/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0150 - mean_squared_error: 0.0150 - accuracy: 0.3783 - val_loss: 0.0144 - val_mean_squared_error: 0.0144 - val_accuracy: 0.3750\n",
      "Epoch 189/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0149 - mean_squared_error: 0.0149 - accuracy: 0.3689 - val_loss: 0.0145 - val_mean_squared_error: 0.0145 - val_accuracy: 0.3775\n",
      "Epoch 190/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0149 - mean_squared_error: 0.0149 - accuracy: 0.3719 - val_loss: 0.0146 - val_mean_squared_error: 0.0146 - val_accuracy: 0.3793\n",
      "Epoch 191/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0150 - mean_squared_error: 0.0150 - accuracy: 0.3719 - val_loss: 0.0144 - val_mean_squared_error: 0.0144 - val_accuracy: 0.3725\n",
      "Epoch 192/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0149 - mean_squared_error: 0.0149 - accuracy: 0.3712 - val_loss: 0.0144 - val_mean_squared_error: 0.0144 - val_accuracy: 0.3744\n",
      "Epoch 193/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0149 - mean_squared_error: 0.0149 - accuracy: 0.3710 - val_loss: 0.0145 - val_mean_squared_error: 0.0145 - val_accuracy: 0.3732\n",
      "Epoch 194/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0149 - mean_squared_error: 0.0149 - accuracy: 0.3818 - val_loss: 0.0144 - val_mean_squared_error: 0.0144 - val_accuracy: 0.3732\n",
      "Epoch 195/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0148 - mean_squared_error: 0.0148 - accuracy: 0.3695 - val_loss: 0.0143 - val_mean_squared_error: 0.0143 - val_accuracy: 0.3762\n",
      "Epoch 196/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0148 - mean_squared_error: 0.0148 - accuracy: 0.3747 - val_loss: 0.0143 - val_mean_squared_error: 0.0143 - val_accuracy: 0.3787\n",
      "Epoch 197/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0149 - mean_squared_error: 0.0149 - accuracy: 0.3747 - val_loss: 0.0143 - val_mean_squared_error: 0.0143 - val_accuracy: 0.3873\n",
      "Epoch 198/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0148 - mean_squared_error: 0.0148 - accuracy: 0.3684 - val_loss: 0.0144 - val_mean_squared_error: 0.0144 - val_accuracy: 0.3762\n",
      "Epoch 199/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0148 - mean_squared_error: 0.0148 - accuracy: 0.3804 - val_loss: 0.0143 - val_mean_squared_error: 0.0143 - val_accuracy: 0.3768\n",
      "Epoch 200/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0148 - mean_squared_error: 0.0148 - accuracy: 0.3746 - val_loss: 0.0143 - val_mean_squared_error: 0.0143 - val_accuracy: 0.3799\n",
      "Epoch 201/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0148 - mean_squared_error: 0.0148 - accuracy: 0.3738 - val_loss: 0.0143 - val_mean_squared_error: 0.0143 - val_accuracy: 0.3762\n",
      "Epoch 202/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0148 - mean_squared_error: 0.0148 - accuracy: 0.3803 - val_loss: 0.0143 - val_mean_squared_error: 0.0143 - val_accuracy: 0.3793\n",
      "Epoch 203/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0148 - mean_squared_error: 0.0148 - accuracy: 0.3779 - val_loss: 0.0143 - val_mean_squared_error: 0.0143 - val_accuracy: 0.3867\n",
      "Epoch 204/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0148 - mean_squared_error: 0.0148 - accuracy: 0.3809 - val_loss: 0.0144 - val_mean_squared_error: 0.0144 - val_accuracy: 0.3842\n",
      "Epoch 205/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0148 - mean_squared_error: 0.0148 - accuracy: 0.3850 - val_loss: 0.0143 - val_mean_squared_error: 0.0143 - val_accuracy: 0.3867\n",
      "Epoch 206/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0148 - mean_squared_error: 0.0148 - accuracy: 0.3901 - val_loss: 0.0143 - val_mean_squared_error: 0.0143 - val_accuracy: 0.3842\n",
      "Epoch 207/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0148 - mean_squared_error: 0.0148 - accuracy: 0.3830 - val_loss: 0.0143 - val_mean_squared_error: 0.0143 - val_accuracy: 0.3812\n",
      "Epoch 208/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0148 - mean_squared_error: 0.0148 - accuracy: 0.3826 - val_loss: 0.0142 - val_mean_squared_error: 0.0142 - val_accuracy: 0.3836\n",
      "Epoch 209/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0148 - mean_squared_error: 0.0148 - accuracy: 0.3903 - val_loss: 0.0142 - val_mean_squared_error: 0.0142 - val_accuracy: 0.3855\n",
      "Epoch 210/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0147 - mean_squared_error: 0.0147 - accuracy: 0.3872 - val_loss: 0.0142 - val_mean_squared_error: 0.0142 - val_accuracy: 0.4033\n",
      "Epoch 211/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0147 - mean_squared_error: 0.0147 - accuracy: 0.3909 - val_loss: 0.0144 - val_mean_squared_error: 0.0144 - val_accuracy: 0.3885\n",
      "Epoch 212/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0148 - mean_squared_error: 0.0148 - accuracy: 0.3790 - val_loss: 0.0143 - val_mean_squared_error: 0.0143 - val_accuracy: 0.3861\n",
      "Epoch 213/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0147 - mean_squared_error: 0.0147 - accuracy: 0.3870 - val_loss: 0.0142 - val_mean_squared_error: 0.0142 - val_accuracy: 0.3885\n",
      "Epoch 214/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0147 - mean_squared_error: 0.0147 - accuracy: 0.3876 - val_loss: 0.0142 - val_mean_squared_error: 0.0142 - val_accuracy: 0.3916\n",
      "Epoch 215/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0147 - mean_squared_error: 0.0147 - accuracy: 0.3898 - val_loss: 0.0142 - val_mean_squared_error: 0.0142 - val_accuracy: 0.3892\n",
      "Epoch 216/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0147 - mean_squared_error: 0.0147 - accuracy: 0.3913 - val_loss: 0.0142 - val_mean_squared_error: 0.0142 - val_accuracy: 0.4076\n",
      "Epoch 217/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0147 - mean_squared_error: 0.0147 - accuracy: 0.3912 - val_loss: 0.0143 - val_mean_squared_error: 0.0143 - val_accuracy: 0.3916\n",
      "Epoch 218/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0147 - mean_squared_error: 0.0147 - accuracy: 0.3966 - val_loss: 0.0143 - val_mean_squared_error: 0.0143 - val_accuracy: 0.3996\n",
      "Epoch 219/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0148 - mean_squared_error: 0.0148 - accuracy: 0.3969 - val_loss: 0.0144 - val_mean_squared_error: 0.0144 - val_accuracy: 0.3990\n",
      "Epoch 220/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0147 - mean_squared_error: 0.0147 - accuracy: 0.3975 - val_loss: 0.0142 - val_mean_squared_error: 0.0142 - val_accuracy: 0.3947\n",
      "Epoch 221/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0147 - mean_squared_error: 0.0147 - accuracy: 0.3960 - val_loss: 0.0142 - val_mean_squared_error: 0.0142 - val_accuracy: 0.3984\n",
      "Epoch 222/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0147 - mean_squared_error: 0.0147 - accuracy: 0.3964 - val_loss: 0.0142 - val_mean_squared_error: 0.0142 - val_accuracy: 0.3916\n",
      "Epoch 223/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - accuracy: 0.4009 - val_loss: 0.0141 - val_mean_squared_error: 0.0141 - val_accuracy: 0.4132\n",
      "Epoch 224/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - accuracy: 0.3953 - val_loss: 0.0143 - val_mean_squared_error: 0.0143 - val_accuracy: 0.4027\n",
      "Epoch 225/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0147 - mean_squared_error: 0.0147 - accuracy: 0.3977 - val_loss: 0.0142 - val_mean_squared_error: 0.0142 - val_accuracy: 0.3996\n",
      "Epoch 226/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0147 - mean_squared_error: 0.0147 - accuracy: 0.3994 - val_loss: 0.0141 - val_mean_squared_error: 0.0141 - val_accuracy: 0.3966\n",
      "Epoch 227/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - accuracy: 0.4021 - val_loss: 0.0141 - val_mean_squared_error: 0.0141 - val_accuracy: 0.4076\n",
      "Epoch 228/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - accuracy: 0.4034 - val_loss: 0.0142 - val_mean_squared_error: 0.0142 - val_accuracy: 0.3978\n",
      "Epoch 229/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - accuracy: 0.3943 - val_loss: 0.0141 - val_mean_squared_error: 0.0141 - val_accuracy: 0.3984\n",
      "Epoch 230/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - accuracy: 0.4029 - val_loss: 0.0143 - val_mean_squared_error: 0.0143 - val_accuracy: 0.4015\n",
      "Epoch 231/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - accuracy: 0.3990 - val_loss: 0.0142 - val_mean_squared_error: 0.0142 - val_accuracy: 0.4002\n",
      "Epoch 232/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - accuracy: 0.4061 - val_loss: 0.0141 - val_mean_squared_error: 0.0141 - val_accuracy: 0.4009\n",
      "Epoch 233/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - accuracy: 0.4026 - val_loss: 0.0141 - val_mean_squared_error: 0.0141 - val_accuracy: 0.4064\n",
      "Epoch 234/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - accuracy: 0.4017 - val_loss: 0.0140 - val_mean_squared_error: 0.0140 - val_accuracy: 0.4095\n",
      "Epoch 235/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0147 - mean_squared_error: 0.0147 - accuracy: 0.4035 - val_loss: 0.0141 - val_mean_squared_error: 0.0141 - val_accuracy: 0.4033\n",
      "Epoch 236/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - accuracy: 0.4077 - val_loss: 0.0142 - val_mean_squared_error: 0.0142 - val_accuracy: 0.4015\n",
      "Epoch 237/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - accuracy: 0.4049 - val_loss: 0.0140 - val_mean_squared_error: 0.0140 - val_accuracy: 0.4015\n",
      "Epoch 238/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0145 - mean_squared_error: 0.0145 - accuracy: 0.4032 - val_loss: 0.0140 - val_mean_squared_error: 0.0140 - val_accuracy: 0.4002\n",
      "Epoch 239/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0145 - mean_squared_error: 0.0145 - accuracy: 0.4075 - val_loss: 0.0142 - val_mean_squared_error: 0.0142 - val_accuracy: 0.4218\n",
      "Epoch 240/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - accuracy: 0.4041 - val_loss: 0.0141 - val_mean_squared_error: 0.0141 - val_accuracy: 0.4052\n",
      "Epoch 241/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0145 - mean_squared_error: 0.0145 - accuracy: 0.4063 - val_loss: 0.0141 - val_mean_squared_error: 0.0141 - val_accuracy: 0.4224\n",
      "Epoch 242/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0145 - mean_squared_error: 0.0145 - accuracy: 0.4091 - val_loss: 0.0140 - val_mean_squared_error: 0.0140 - val_accuracy: 0.4033\n",
      "Epoch 243/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0145 - mean_squared_error: 0.0145 - accuracy: 0.4051 - val_loss: 0.0140 - val_mean_squared_error: 0.0140 - val_accuracy: 0.4039\n",
      "Epoch 244/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0145 - mean_squared_error: 0.0145 - accuracy: 0.4104 - val_loss: 0.0140 - val_mean_squared_error: 0.0140 - val_accuracy: 0.4046\n",
      "Epoch 245/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0145 - mean_squared_error: 0.0145 - accuracy: 0.4072 - val_loss: 0.0141 - val_mean_squared_error: 0.0141 - val_accuracy: 0.4076\n",
      "Epoch 246/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0145 - mean_squared_error: 0.0145 - accuracy: 0.4074 - val_loss: 0.0140 - val_mean_squared_error: 0.0140 - val_accuracy: 0.4163\n",
      "Epoch 247/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0145 - mean_squared_error: 0.0145 - accuracy: 0.4100 - val_loss: 0.0140 - val_mean_squared_error: 0.0140 - val_accuracy: 0.4064\n",
      "Epoch 248/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0145 - mean_squared_error: 0.0145 - accuracy: 0.4135 - val_loss: 0.0140 - val_mean_squared_error: 0.0140 - val_accuracy: 0.3990\n",
      "Epoch 249/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0145 - mean_squared_error: 0.0145 - accuracy: 0.4044 - val_loss: 0.0140 - val_mean_squared_error: 0.0140 - val_accuracy: 0.4076\n",
      "Epoch 250/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0145 - mean_squared_error: 0.0145 - accuracy: 0.4092 - val_loss: 0.0140 - val_mean_squared_error: 0.0140 - val_accuracy: 0.4113\n",
      "Epoch 251/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0145 - mean_squared_error: 0.0145 - accuracy: 0.4171 - val_loss: 0.0141 - val_mean_squared_error: 0.0141 - val_accuracy: 0.4021\n",
      "Epoch 252/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0145 - mean_squared_error: 0.0145 - accuracy: 0.4055 - val_loss: 0.0141 - val_mean_squared_error: 0.0141 - val_accuracy: 0.4021\n",
      "Epoch 253/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0145 - mean_squared_error: 0.0145 - accuracy: 0.4097 - val_loss: 0.0140 - val_mean_squared_error: 0.0140 - val_accuracy: 0.4015\n",
      "Epoch 254/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0145 - mean_squared_error: 0.0145 - accuracy: 0.4041 - val_loss: 0.0139 - val_mean_squared_error: 0.0139 - val_accuracy: 0.4039\n",
      "Epoch 255/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0144 - mean_squared_error: 0.0144 - accuracy: 0.4121 - val_loss: 0.0141 - val_mean_squared_error: 0.0141 - val_accuracy: 0.4064\n",
      "Epoch 256/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0145 - mean_squared_error: 0.0145 - accuracy: 0.4104 - val_loss: 0.0141 - val_mean_squared_error: 0.0141 - val_accuracy: 0.4070\n",
      "Epoch 257/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0144 - mean_squared_error: 0.0144 - accuracy: 0.4084 - val_loss: 0.0139 - val_mean_squared_error: 0.0139 - val_accuracy: 0.4187\n",
      "Epoch 258/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0144 - mean_squared_error: 0.0144 - accuracy: 0.4138 - val_loss: 0.0139 - val_mean_squared_error: 0.0139 - val_accuracy: 0.4027\n",
      "Epoch 259/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0144 - mean_squared_error: 0.0144 - accuracy: 0.4126 - val_loss: 0.0139 - val_mean_squared_error: 0.0139 - val_accuracy: 0.4058\n",
      "Epoch 260/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0144 - mean_squared_error: 0.0144 - accuracy: 0.4047 - val_loss: 0.0139 - val_mean_squared_error: 0.0139 - val_accuracy: 0.4156\n",
      "Epoch 261/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0144 - mean_squared_error: 0.0144 - accuracy: 0.4171 - val_loss: 0.0139 - val_mean_squared_error: 0.0139 - val_accuracy: 0.4070\n",
      "Epoch 262/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0144 - mean_squared_error: 0.0144 - accuracy: 0.4117 - val_loss: 0.0139 - val_mean_squared_error: 0.0139 - val_accuracy: 0.3996\n",
      "Epoch 263/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - accuracy: 0.4154 - val_loss: 0.0139 - val_mean_squared_error: 0.0139 - val_accuracy: 0.4119\n",
      "Epoch 264/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0144 - mean_squared_error: 0.0144 - accuracy: 0.4189 - val_loss: 0.0140 - val_mean_squared_error: 0.0140 - val_accuracy: 0.4039\n",
      "Epoch 265/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0144 - mean_squared_error: 0.0144 - accuracy: 0.4226 - val_loss: 0.0139 - val_mean_squared_error: 0.0139 - val_accuracy: 0.4064\n",
      "Epoch 266/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0144 - mean_squared_error: 0.0144 - accuracy: 0.4129 - val_loss: 0.0140 - val_mean_squared_error: 0.0140 - val_accuracy: 0.4095\n",
      "Epoch 267/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0144 - mean_squared_error: 0.0144 - accuracy: 0.4135 - val_loss: 0.0139 - val_mean_squared_error: 0.0139 - val_accuracy: 0.4113\n",
      "Epoch 268/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - accuracy: 0.4141 - val_loss: 0.0139 - val_mean_squared_error: 0.0139 - val_accuracy: 0.4169\n",
      "Epoch 269/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0144 - mean_squared_error: 0.0144 - accuracy: 0.4181 - val_loss: 0.0139 - val_mean_squared_error: 0.0139 - val_accuracy: 0.4126\n",
      "Epoch 270/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0144 - mean_squared_error: 0.0144 - accuracy: 0.4155 - val_loss: 0.0139 - val_mean_squared_error: 0.0139 - val_accuracy: 0.4126\n",
      "Epoch 271/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0144 - mean_squared_error: 0.0144 - accuracy: 0.4164 - val_loss: 0.0138 - val_mean_squared_error: 0.0138 - val_accuracy: 0.4236\n",
      "Epoch 272/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - accuracy: 0.4188 - val_loss: 0.0139 - val_mean_squared_error: 0.0139 - val_accuracy: 0.4083\n",
      "Epoch 273/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - accuracy: 0.4151 - val_loss: 0.0138 - val_mean_squared_error: 0.0138 - val_accuracy: 0.4249\n",
      "Epoch 274/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - accuracy: 0.4206 - val_loss: 0.0138 - val_mean_squared_error: 0.0138 - val_accuracy: 0.4113\n",
      "Epoch 275/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - accuracy: 0.4234 - val_loss: 0.0138 - val_mean_squared_error: 0.0138 - val_accuracy: 0.4200\n",
      "Epoch 276/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - accuracy: 0.4268 - val_loss: 0.0139 - val_mean_squared_error: 0.0139 - val_accuracy: 0.4169\n",
      "Epoch 277/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - accuracy: 0.4169 - val_loss: 0.0138 - val_mean_squared_error: 0.0138 - val_accuracy: 0.4304\n",
      "Epoch 278/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - accuracy: 0.4294 - val_loss: 0.0139 - val_mean_squared_error: 0.0139 - val_accuracy: 0.4200\n",
      "Epoch 279/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - accuracy: 0.4175 - val_loss: 0.0138 - val_mean_squared_error: 0.0138 - val_accuracy: 0.4218\n",
      "Epoch 280/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - accuracy: 0.4157 - val_loss: 0.0138 - val_mean_squared_error: 0.0138 - val_accuracy: 0.4267\n",
      "Epoch 281/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - accuracy: 0.4232 - val_loss: 0.0138 - val_mean_squared_error: 0.0138 - val_accuracy: 0.4138\n",
      "Epoch 282/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - accuracy: 0.4152 - val_loss: 0.0137 - val_mean_squared_error: 0.0137 - val_accuracy: 0.4224\n",
      "Epoch 283/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0142 - mean_squared_error: 0.0142 - accuracy: 0.4246 - val_loss: 0.0139 - val_mean_squared_error: 0.0139 - val_accuracy: 0.4212\n",
      "Epoch 284/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - accuracy: 0.4181 - val_loss: 0.0138 - val_mean_squared_error: 0.0138 - val_accuracy: 0.4206\n",
      "Epoch 285/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0142 - mean_squared_error: 0.0142 - accuracy: 0.4214 - val_loss: 0.0137 - val_mean_squared_error: 0.0137 - val_accuracy: 0.4286\n",
      "Epoch 286/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - accuracy: 0.4238 - val_loss: 0.0139 - val_mean_squared_error: 0.0139 - val_accuracy: 0.4255\n",
      "Epoch 287/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - accuracy: 0.4232 - val_loss: 0.0139 - val_mean_squared_error: 0.0139 - val_accuracy: 0.4249\n",
      "Epoch 288/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0142 - mean_squared_error: 0.0142 - accuracy: 0.4200 - val_loss: 0.0138 - val_mean_squared_error: 0.0138 - val_accuracy: 0.4089\n",
      "Epoch 289/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - accuracy: 0.4280 - val_loss: 0.0138 - val_mean_squared_error: 0.0138 - val_accuracy: 0.4138\n",
      "Epoch 290/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0142 - mean_squared_error: 0.0142 - accuracy: 0.4234 - val_loss: 0.0138 - val_mean_squared_error: 0.0138 - val_accuracy: 0.4132\n",
      "Epoch 291/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - accuracy: 0.4272 - val_loss: 0.0139 - val_mean_squared_error: 0.0139 - val_accuracy: 0.4163\n",
      "Epoch 292/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0142 - mean_squared_error: 0.0142 - accuracy: 0.4243 - val_loss: 0.0138 - val_mean_squared_error: 0.0138 - val_accuracy: 0.4526\n",
      "Epoch 293/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0142 - mean_squared_error: 0.0142 - accuracy: 0.4212 - val_loss: 0.0137 - val_mean_squared_error: 0.0137 - val_accuracy: 0.4163\n",
      "Epoch 294/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0142 - mean_squared_error: 0.0142 - accuracy: 0.4229 - val_loss: 0.0139 - val_mean_squared_error: 0.0139 - val_accuracy: 0.4317\n",
      "Epoch 295/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0142 - mean_squared_error: 0.0142 - accuracy: 0.4277 - val_loss: 0.0137 - val_mean_squared_error: 0.0137 - val_accuracy: 0.4150\n",
      "Epoch 296/300\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - accuracy: 0.4231 - val_loss: 0.0138 - val_mean_squared_error: 0.0138 - val_accuracy: 0.4378\n",
      "Epoch 297/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0142 - mean_squared_error: 0.0142 - accuracy: 0.4309 - val_loss: 0.0137 - val_mean_squared_error: 0.0137 - val_accuracy: 0.4267\n",
      "Epoch 298/300\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.0142 - mean_squared_error: 0.0142 - accuracy: 0.4263 - val_loss: 0.0138 - val_mean_squared_error: 0.0138 - val_accuracy: 0.4193\n",
      "Epoch 299/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0142 - mean_squared_error: 0.0142 - accuracy: 0.4223 - val_loss: 0.0138 - val_mean_squared_error: 0.0138 - val_accuracy: 0.4280\n",
      "Epoch 300/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0142 - mean_squared_error: 0.0142 - accuracy: 0.4275 - val_loss: 0.0139 - val_mean_squared_error: 0.0139 - val_accuracy: 0.4273\n"
     ]
    }
   ],
   "source": [
    "autoencoder.compile(optimizer='adam',\n",
    "                    loss='mean_squared_error',\n",
    "                    metrics=[tf.keras.metrics.mean_squared_error, 'accuracy'])\n",
    "\n",
    "history = autoencoder.fit(x=x_train, y=x_train,\n",
    "                epochs=300, batch_size=256,\n",
    "                validation_split=0.2,\n",
    "                # validation_data=(x_valid, x_valid)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend([\"training loss\", \"validation loss\"])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"MSE on the model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 0s/step\n",
      "15/15 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# function to predict and compute mse\n",
    "def predict_and_compute_mse(data, model):\n",
    "    data_hat = model.predict(data)\n",
    "    # mse = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)(\n",
    "    #     data, data_hat).numpy()\n",
    "    mse = np.mean(np.power(data - data_hat,2),axis=1)\n",
    "    # mse = tf.keras.losses.mean_squared_error(\n",
    "    #     data, data_hat).numpy()\n",
    "    return mse, data_hat\n",
    "\n",
    "# compute mse on validation data\n",
    "x_valid_fraud = x_valid.loc[y_valid == 1]\n",
    "x_valid_non_fraud = x_valid.loc[y_valid == 0]\n",
    "mse_valid_fraud, x_hat_valid_fraud = predict_and_compute_mse(x_valid_fraud, autoencoder)\n",
    "mse_valid_non_fraud, x_hat_valid_non_fraud = predict_and_compute_mse(x_valid_non_fraud, autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots histograms of mse for fraud and non fraud cases\n",
    "def plot_histograms(mse_fraud, mse_non_fraud, name):\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.hist(mse_non_fraud, color='turquoise', alpha=0.7, density=True)\n",
    "    plt.hist(mse_fraud, color='orange', alpha=0.7, density=True)\n",
    "    plt.legend([\"non fraud\", \"fraud\"])\n",
    "    plt.title(\"MSE histogram: \" + name)\n",
    "    plt.xlabel(\"MSE\")\n",
    "    plt.ylabel(\"count\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_histograms(mse_valid_fraud, mse_valid_non_fraud, \"Validation data\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Build the network architecture - Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 00m 05s]\n",
      "val_mean_squared_error: 0.15168510377407074\n",
      "\n",
      "Best val_mean_squared_error So Far: 0.15168510377407074\n",
      "Total elapsed time: 00h 00m 11s\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "37                |30                |num_units_l1\n",
      "20                |25                |num_units_l2\n",
      "18                |19                |num_units_l3\n",
      "0.15156           |0.21876           |dropout_rate\n",
      "adam              |rmsprop           |optimizer\n",
      "2                 |2                 |tuner/epochs\n",
      "0                 |0                 |tuner/initial_epoch\n",
      "2                 |2                 |tuner/bracket\n",
      "0                 |0                 |tuner/round\n",
      "\n",
      "Epoch 1/2\n",
      "169/178 [===========================>..] - ETA: 0s - loss: 0.2378 - mean_squared_error: 0.2378"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Soumya\\Repo\\TejaSoumya\\Term 2\\DL\\Preprep.ipynb Cell 44\u001b[0m in \u001b[0;36m<cell line: 124>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Soumya/Repo/TejaSoumya/Term%202/DL/Preprep.ipynb#Y265sZmlsZQ%3D%3D?line=120'>121</a>\u001b[0m x_tr_nf, x_va_nf, y_tr_nf, y_va_nf \u001b[39m=\u001b[39m train_test_split(x_train, y_train, train_size\u001b[39m=\u001b[39m\u001b[39m0.7\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Soumya/Repo/TejaSoumya/Term%202/DL/Preprep.ipynb#Y265sZmlsZQ%3D%3D?line=122'>123</a>\u001b[0m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mbackend\u001b[39m.\u001b[39mclear_session()\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Soumya/Repo/TejaSoumya/Term%202/DL/Preprep.ipynb#Y265sZmlsZQ%3D%3D?line=123'>124</a>\u001b[0m tuner\u001b[39m.\u001b[39;49msearch(x_tr_nf, x_tr_nf, \n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Soumya/Repo/TejaSoumya/Term%202/DL/Preprep.ipynb#Y265sZmlsZQ%3D%3D?line=124'>125</a>\u001b[0m               validation_data\u001b[39m=\u001b[39;49m(x_va_nf, x_va_nf)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Soumya/Repo/TejaSoumya/Term%202/DL/Preprep.ipynb#Y265sZmlsZQ%3D%3D?line=125'>126</a>\u001b[0m               )\n",
      "File \u001b[1;32mc:\\Users\\Soumya\\anaconda3\\Anaconda\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:226\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m--> 226\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_run_and_update_trial(trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs)\n\u001b[0;32m    227\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_end(trial)\n\u001b[0;32m    228\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_search_end()\n",
      "File \u001b[1;32mc:\\Users\\Soumya\\anaconda3\\Anaconda\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:266\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[0;32m    265\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 266\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_and_update_trial(trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs)\n\u001b[0;32m    267\u001b[0m         trial\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m trial_module\u001b[39m.\u001b[39mTrialStatus\u001b[39m.\u001b[39mCOMPLETED\n\u001b[0;32m    268\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Soumya\\anaconda3\\Anaconda\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:231\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[1;32m--> 231\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_trial(trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs)\n\u001b[0;32m    232\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mget_trial(trial\u001b[39m.\u001b[39mtrial_id)\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mexists(\n\u001b[0;32m    233\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective\u001b[39m.\u001b[39mname\n\u001b[0;32m    234\u001b[0m     ):\n\u001b[0;32m    235\u001b[0m         \u001b[39m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         \u001b[39m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[0;32m    237\u001b[0m         \u001b[39m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    239\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe use case of calling \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    240\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    246\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m    247\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Soumya\\anaconda3\\Anaconda\\lib\\site-packages\\keras_tuner\\tuners\\hyperband.py:419\u001b[0m, in \u001b[0;36mHyperband.run_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    417\u001b[0m     fit_kwargs[\u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m hp\u001b[39m.\u001b[39mvalues[\u001b[39m\"\u001b[39m\u001b[39mtuner/epochs\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    418\u001b[0m     fit_kwargs[\u001b[39m\"\u001b[39m\u001b[39minitial_epoch\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m hp\u001b[39m.\u001b[39mvalues[\u001b[39m\"\u001b[39m\u001b[39mtuner/initial_epoch\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m--> 419\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrun_trial(trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Soumya\\anaconda3\\Anaconda\\lib\\site-packages\\keras_tuner\\engine\\tuner.py:287\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(model_checkpoint)\n\u001b[0;32m    286\u001b[0m     copied_kwargs[\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m callbacks\n\u001b[1;32m--> 287\u001b[0m     obj_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_and_fit_model(trial, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    289\u001b[0m     histories\u001b[39m.\u001b[39mappend(obj_value)\n\u001b[0;32m    290\u001b[0m \u001b[39mreturn\u001b[39;00m histories\n",
      "File \u001b[1;32mc:\\Users\\Soumya\\anaconda3\\Anaconda\\lib\\site-packages\\keras_tuner\\engine\\tuner.py:214\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m hp \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39mhyperparameters\n\u001b[0;32m    213\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_build(hp)\n\u001b[1;32m--> 214\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhypermodel\u001b[39m.\u001b[39mfit(hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    215\u001b[0m tuner_utils\u001b[39m.\u001b[39mvalidate_trial_results(\n\u001b[0;32m    216\u001b[0m     results, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective, \u001b[39m\"\u001b[39m\u001b[39mHyperModel.fit()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    217\u001b[0m )\n\u001b[0;32m    218\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\Users\\Soumya\\anaconda3\\Anaconda\\lib\\site-packages\\keras_tuner\\engine\\hypermodel.py:144\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[1;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    121\u001b[0m     \u001b[39m\"\"\"Train the model.\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \n\u001b[0;32m    123\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[39m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 144\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39mfit(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Soumya\\anaconda3\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Soumya\\anaconda3\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py:1694\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1679\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_eval_data_handler\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39mget_data_handler(\n\u001b[0;32m   1681\u001b[0m         x\u001b[39m=\u001b[39mval_x,\n\u001b[0;32m   1682\u001b[0m         y\u001b[39m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1692\u001b[0m         steps_per_execution\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution,\n\u001b[0;32m   1693\u001b[0m     )\n\u001b[1;32m-> 1694\u001b[0m val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n\u001b[0;32m   1695\u001b[0m     x\u001b[39m=\u001b[39;49mval_x,\n\u001b[0;32m   1696\u001b[0m     y\u001b[39m=\u001b[39;49mval_y,\n\u001b[0;32m   1697\u001b[0m     sample_weight\u001b[39m=\u001b[39;49mval_sample_weight,\n\u001b[0;32m   1698\u001b[0m     batch_size\u001b[39m=\u001b[39;49mvalidation_batch_size \u001b[39mor\u001b[39;49;00m batch_size,\n\u001b[0;32m   1699\u001b[0m     steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m   1700\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1701\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   1702\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   1703\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   1704\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1705\u001b[0m     _use_cached_eval_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1706\u001b[0m )\n\u001b[0;32m   1707\u001b[0m val_logs \u001b[39m=\u001b[39m {\n\u001b[0;32m   1708\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()\n\u001b[0;32m   1709\u001b[0m }\n\u001b[0;32m   1710\u001b[0m epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32mc:\\Users\\Soumya\\anaconda3\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Soumya\\anaconda3\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py:2040\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   2036\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   2037\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m   2038\u001b[0m ):\n\u001b[0;32m   2039\u001b[0m     callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 2040\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_function(iterator)\n\u001b[0;32m   2041\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   2042\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Soumya\\anaconda3\\Anaconda\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Soumya\\anaconda3\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Soumya\\anaconda3\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:952\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    947\u001b[0m   _, _, filtered_flat_args \u001b[39m=\u001b[39m (\n\u001b[0;32m    948\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn\u001b[39m.\u001b[39m_function_spec  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    949\u001b[0m       \u001b[39m.\u001b[39mcanonicalize_function_inputs(\n\u001b[0;32m    950\u001b[0m           args, kwds))\n\u001b[0;32m    951\u001b[0m   \u001b[39m# If we did not create any variables the trace we have is good enough.\u001b[39;00m\n\u001b[1;32m--> 952\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_concrete_variable_creation_fn\u001b[39m.\u001b[39;49m_call_flat(   \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    953\u001b[0m       filtered_flat_args,\n\u001b[0;32m    954\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_concrete_variable_creation_fn\u001b[39m.\u001b[39;49mcaptured_inputs)\n\u001b[0;32m    956\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfn_with_cond\u001b[39m(inner_args, inner_kwds, inner_filtered_flat_args):\n\u001b[0;32m    957\u001b[0m   \u001b[39m\"\"\"Conditionally runs initialization if it's needed.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Soumya\\anaconda3\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m     args,\n\u001b[0;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1750\u001b[0m     executing_eagerly)\n\u001b[0;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Soumya\\anaconda3\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Soumya\\anaconda3\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# define train model for hyperparameter tuning\n",
    "def build(hp):\n",
    "    num_units_l1 = hp.Int('num_units_l1', min_value = 30, max_value=40)\n",
    "    num_units_l2 = hp.Int('num_units_l2', min_value = 20, max_value=30)\n",
    "    num_units_l3 = hp.Int('num_units_l3', min_value = 10, max_value=20)\n",
    "    # num_units_l4 = hp.Int('num_units_l4', min_value = 20, max_value=25)\n",
    "    # num_units_l5 = hp.Int('num_units_l5', min_value = 10, max_value=20)\n",
    "\n",
    "    dropout_rate = hp.Float('dropout_rate', min_value = 0.1, max_value=0.3)\n",
    "\n",
    "    # learning_rate = hp.Float('learning_rate', min_value = 0.0001, max_value=0.1, sampling='log') \n",
    "    learning_rate = 0.001\n",
    "\n",
    "    optimizers = hp.Choice('optimizer', values=['rmsprop','adam'])\n",
    "\n",
    "    # batch_size = hp.Int('batch_size', min_value=16, max_value=128)\n",
    "    batch_size = 128\n",
    "    # epochs_until_change = 5\n",
    "    # steps_per_epoch = x_train.shape[0] / batch_size\n",
    "    # steps = epochs_until_change * steps_per_epoch\n",
    "    # learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=init_learning_rate, \n",
    "    #                                                                decay_steps=steps, decay_rate=0.1)\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "        # encoder\n",
    "        tf.keras.layers.Input(shape=(x_train.shape[1], )),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(num_units_l1, kernel_initializer=\"he_normal\", name=\"encoder_l1\",\n",
    "                            #   kernel_regularizer=tf.keras.regularizers.L1(0.01)\n",
    "                              ),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation(\"relu\"),\n",
    "\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(num_units_l2, kernel_initializer=\"he_normal\", name=\"encoder_l2\",\n",
    "                            #   kernel_regularizer=tf.keras.regularizers.L1(0.01)\n",
    "                              ),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(num_units_l3, kernel_initializer=\"he_normal\", name=\"encoder_l3\",\n",
    "                            #   kernel_regularizer=tf.keras.regularizers.L1(0.01)\n",
    "                              ),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "\n",
    "        # # tf.keras.layers.Dropout(dropout_rate),\n",
    "        # tf.keras.layers.Dense(num_units_l4, kernel_initializer=\"he_normal\", name=\"encoder_l4\",\n",
    "        #                       kernel_regularizer=tf.keras.regularizers.L1(0.01)\n",
    "        #                       ),\n",
    "        # tf.keras.layers.BatchNormalization(),\n",
    "        # tf.keras.layers.Activation('relu'),\n",
    "        # # tf.keras.layers.Dropout(dropout_rate),\n",
    "        # tf.keras.layers.Dense(num_units_l5, kernel_initializer=\"he_normal\", name=\"encoder_l5\",\n",
    "        #                       kernel_regularizer=tf.keras.regularizers.L1(0.01)\n",
    "        #                       ),\n",
    "        # tf.keras.layers.BatchNormalization(),\n",
    "        # tf.keras.layers.Activation('relu'),\n",
    "\n",
    "        # decoder\n",
    "\n",
    "        # # tf.keras.layers.Dropout(dropout_rate),\n",
    "        # tf.keras.layers.Dense(num_units_l4, kernel_initializer=\"he_normal\", name=\"decoder_l0\",\n",
    "        #                       kernel_regularizer=tf.keras.regularizers.L1(0.01)\n",
    "        #                       ),\n",
    "        # tf.keras.layers.BatchNormalization(),\n",
    "        # tf.keras.layers.Activation('relu'),\n",
    "\n",
    "        # # tf.keras.layers.Dropout(dropout_rate),\n",
    "        # tf.keras.layers.Dense(num_units_l3, kernel_initializer=\"he_normal\", name=\"decoder_l1\",\n",
    "        #                       kernel_regularizer=tf.keras.regularizers.L1(0.01)\n",
    "        #                       ),\n",
    "        # tf.keras.layers.BatchNormalization(),\n",
    "        # tf.keras.layers.Activation('relu'),\n",
    "\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(num_units_l2, kernel_initializer=\"he_normal\", name=\"decoder_l2\",\n",
    "                            #   kernel_regularizer=tf.keras.regularizers.L1(0.01)\n",
    "                              ),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(num_units_l1, kernel_initializer=\"he_normal\", name=\"decoder_l3\",\n",
    "                            #   kernel_regularizer=tf.keras.regularizers.L1(0.01)\n",
    "                              ),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(x_train.shape[1], kernel_initializer=\"glorot_uniform\", name=\"output_layer\",\n",
    "                            #   kernel_regularizer=tf.keras.regularizers.L1(0.01)\n",
    "                              ),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Activation('sigmoid')])\n",
    "\n",
    "    if optimizers == \"adam\":\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizers == \"rmsprop\":\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=tf.keras.metrics.mean_squared_error\n",
    "                #   metrics='auc_from_mse'\n",
    "                  )\n",
    "\n",
    "    return model\n",
    "\n",
    "tuner = kt.Hyperband(build,\n",
    "                     'val_mean_squared_error',\n",
    "                    #  kt.Objective(\"loss\", direction=\"min\"),    # kt.Objective(\"loss\", direction=\"min\"),\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='logs',\n",
    "                     project_name='autoencoder' + str(datetime.datetime.now().timestamp()))\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n",
    "x_tr_nf, x_va_nf, y_tr_nf, y_va_nf = train_test_split(x_train, y_train, train_size=0.7, shuffle=True)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "tuner.search(x_tr_nf, x_tr_nf, \n",
    "              validation_data=(x_va_nf, x_va_nf)\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps=tuner.get_best_hyperparameters()[0]\n",
    "print(best_hps['num_units_l1'])\n",
    "print(best_hps['num_units_l2'])\n",
    "print(best_hps['num_units_l3'])\n",
    "# print(best_hps['num_units_l4'])\n",
    "# print(best_hps['num_units_l5'])\n",
    "print(best_hps['optimizer'])\n",
    "print(best_hps['dropout_rate'])\n",
    "print(best_hps['learning_rate'])\n",
    "print(best_hps['batch_size'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the values that we got using val_loss\n",
    "48\n",
    "38\n",
    "26\n",
    "13\n",
    "adam\n",
    "0.27755988158984424"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model with the best parameters found\n",
    "num_units_l1 = 32 #best_hps['num_units_l1']\n",
    "num_units_l2 = 16 #best_hps['num_units_l2']\n",
    "num_units_l3 = 10 #best_hps['num_units_l3']\n",
    "num_units_l4 = 8 #best_hps['num_units_l4']\n",
    "# num_units_l5 = best_hps['num_units_l5']\n",
    "optimizer_choice = 'adam' #best_hps['optimizer']\n",
    "dropout_rate = 0.1 #best_hps['dropout_rate']\n",
    "learning_rate = 0.001 #best_hps['learning_rate']\n",
    "batch_size = 256# best_hps['batch_size']\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    # encoder\n",
    "    tf.keras.layers.Input(shape=(x_train.shape[1], )),\n",
    "\n",
    "    tf.keras.layers.Dropout(dropout_rate),\n",
    "    # tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(num_units_l1, kernel_initializer=\"he_normal\", name=\"encoder_l1\",\n",
    "                        #   kernel_regularizer=tf.keras.regularizers.L1(0.01)\n",
    "                          ),\n",
    "    \n",
    "    tf.keras.layers.Activation(\"elu\"),\n",
    "\n",
    "    tf.keras.layers.Dropout(dropout_rate),\n",
    "    # tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(num_units_l2, kernel_initializer=\"he_normal\", name=\"encoder_l2\",\n",
    "                        #   kernel_regularizer=tf.keras.regularizers.L1(0.01)\n",
    "                          ),\n",
    "    \n",
    "    tf.keras.layers.Activation('relu'),\n",
    "\n",
    "    tf.keras.layers.Dropout(dropout_rate),\n",
    "    # tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(num_units_l3, kernel_initializer=\"he_normal\", name=\"encoder_l3\",\n",
    "                        #   kernel_regularizer=tf.keras.regularizers.L1(0.01)\n",
    "                          ),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "\n",
    "    tf.keras.layers.Dropout(dropout_rate),\n",
    "    tf.keras.layers.Dense(num_units_l4, kernel_initializer=\"he_normal\", name=\"encoder_l4\",\n",
    "                          # kernel_regularizer=tf.keras.regularizers.L1(0.01)\n",
    "                          ),\n",
    "    # tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "\n",
    "    # # tf.keras.layers.Dropout(dropout_rate),\n",
    "    # tf.keras.layers.Dense(num_units_l5, kernel_initializer=\"he_normal\", name=\"encoder_l5\",\n",
    "    #                       kernel_regularizer=tf.keras.regularizers.L1(0.01)\n",
    "    #                       ),\n",
    "    # tf.keras.layers.BatchNormalization(),\n",
    "    # tf.keras.layers.Activation('relu'),\n",
    "\n",
    "    # decoder\n",
    "\n",
    "    # # tf.keras.layers.Dropout(dropout_rate),\n",
    "    # tf.keras.layers.Dense(num_units_l4, kernel_initializer=\"he_normal\", name=\"decoder_l0\",\n",
    "    #                       kernel_regularizer=tf.keras.regularizers.L1(0.01)\n",
    "    #                       ),\n",
    "    # tf.keras.layers.BatchNormalization(),\n",
    "    # tf.keras.layers.Activation('relu'),\n",
    "    \n",
    "    tf.keras.layers.Dropout(dropout_rate),\n",
    "    tf.keras.layers.Dense(num_units_l3, kernel_initializer=\"he_normal\", name=\"decoder_l1\",\n",
    "                          kernel_regularizer=tf.keras.regularizers.L1(0.01)\n",
    "                          ),\n",
    "    # tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "\n",
    "    tf.keras.layers.Dropout(dropout_rate),\n",
    "    # tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(num_units_l2, kernel_initializer=\"he_normal\", name=\"decoder_l2\",\n",
    "                        #   kernel_regularizer=tf.keras.regularizers.L1(0.01)\n",
    "                          ),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "\n",
    "    tf.keras.layers.Dropout(dropout_rate),\n",
    "    # tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(num_units_l1, kernel_initializer=\"he_normal\", name=\"decoder_l3\",\n",
    "                        #   kernel_regularizer=tf.keras.regularizers.L1(0.01)\n",
    "                          ),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "\n",
    "    tf.keras.layers.Dropout(dropout_rate),\n",
    "    # tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(x_train.shape[1], kernel_initializer=\"he_normal\", name=\"output_layer\",\n",
    "                        #   kernel_regularizer=tf.keras.regularizers.L1(0.01)\n",
    "                          ),\n",
    "    tf.keras.layers.Activation('sigmoid')])\n",
    "\n",
    "# epochs_until_change = 10\n",
    "# steps_per_epoch = x_train.shape[0] / batch_size\n",
    "# steps = epochs_until_change * steps_per_epoch\n",
    "\n",
    "# learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=init_learning_rate, decay_steps=steps, decay_rate=0.1)\n",
    "\n",
    "if optimizer_choice == \"adam\":\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
    "elif optimizer_choice == \"rmsprop\":\n",
    "    optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate, rho=0.9, epsilon=1e-07, momentum=0.0)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='mean_squared_error',\n",
    "              metrics=tf.keras.metrics.mean_squared_error\n",
    "            #   metrics='auc_from_mse'\n",
    "              )\n",
    "\n",
    "cb = tf.keras.callbacks.EarlyStopping(monitor='val_mean_squared_error', min_delta=0.0001, patience=20, restore_best_weights=True)\n",
    "history = model.fit(x_tr_nf, x_tr_nf, batch_size=batch_size, epochs=500, callbacks=[cb],\n",
    "                    validation_data=(x_va_nf, x_va_nf)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "# plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['mean_squared_error'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "plt.plot(history.history['val_mean_squared_error'])\n",
    "plt.legend([\n",
    "    # \"training loss\", \n",
    "    \"mean_squared_error\", \n",
    "    # \"validation loss\", \n",
    "    \"val_mean_squared_error\"])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"MSE on the model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute mse on validation data\n",
    "x_valid_fraud = x_valid.loc[y_valid == 1, :]\n",
    "x_valid_non_fraud = x_valid.loc[y_valid == 0, :]\n",
    "mse_valid_fraud, x_hat_valid_fraud = predict_and_compute_mse(x_valid_fraud, model)\n",
    "mse_valid_non_fraud, x_hat_valid_non_fraud = predict_and_compute_mse(x_valid_non_fraud, model)\n",
    "\n",
    "mse_tr_nf, x_hat_tr_nf = predict_and_compute_mse(x_tr_nf, model)\n",
    "mse_va_nf, x_hat_va_nf = predict_and_compute_mse(x_va_nf, model)\n",
    "\n",
    "plt.plot(mse_valid_fraud, 'r.')\n",
    "plt.plot(mse_valid_non_fraud, 'b.')\n",
    "\n",
    "# plt.plot(mse_tr_nf, \"g.\")\n",
    "# plt.plot(mse_va_nf, \"k.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "plot_histograms(mse_valid_fraud, mse_valid_non_fraud, \"Validation data\")\n",
    "# plot_histograms(mse_tr_nf, mse_va_nf, \"Validation data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplots(1,2,figsize=(10,7))\n",
    "plt.suptitle(\"Training set - non fraud data\")\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(x_tr_nf.to_numpy(), aspect='auto', cmap=\"jet\", interpolation=None, vmin=0, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "plt.title(\"real features\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(x_hat_tr_nf, aspect='auto', cmap=\"jet\", interpolation=None,vmin=0, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "plt.title(\"reconstructed features\")\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplots(1,2,figsize=(10,7))\n",
    "plt.suptitle(\"Validation set - non fraud data\")\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(x_valid_non_fraud.to_numpy(), aspect='auto', cmap=\"jet\", interpolation=None, vmin=0, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "plt.title(\"real features\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(x_hat_valid_non_fraud, aspect='auto', cmap=\"jet\", interpolation=None, vmin=0, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "plt.title(\"reconstructed features\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplots(1,2,figsize=(10,7))\n",
    "plt.suptitle(\"Validation set - fraud data\")\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(x_valid_fraud.to_numpy(), aspect='auto', cmap=\"jet\", interpolation=None, vmin=0, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "plt.title(\"real features\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(x_hat_valid_fraud, aspect='auto', cmap=\"jet\", interpolation=None, vmin=0, vmax=1)\n",
    "plt.colorbar()\n",
    "# plt.axis('off')\n",
    "plt.title(\"reconstructed features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, auc, roc_curve\n",
    "\n",
    "mse_valid, x_hat_valid = predict_and_compute_mse(x_valid, model)\n",
    "precisions = []\n",
    "recalls = []\n",
    "thresholds = np.linspace(0, 0.08, 10)\n",
    "for t in thresholds:\n",
    "    y_pred = mse_valid > t\n",
    "    precisions.append(precision_score(y_valid, y_pred))\n",
    "    recalls.append(recall_score(y_valid, y_pred))\n",
    "\n",
    "\n",
    "# fpr, tpr, thresholds = roc_curve(y_valid, mse_valid, pos_label=2)\n",
    "# print(auc(fpr, tpr))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(thresholds, precisions)\n",
    "plt.plot(thresholds, recalls)\n",
    "_=plt.legend([\"precision\", \"recall\"])\n",
    "\n",
    "threshold = np.percentile(mse_tr_nf, 60)\n",
    "print(threshold)\n",
    "y_pred = mse_valid > threshold\n",
    "cmat = confusion_matrix(y_valid.to_numpy(), y_pred)\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(cmat, annot=True, xticklabels=[\"non fraud\", \"fraud\"], yticklabels=[\"non fraud\", \"fraud\"])\n",
    "plt.xlabel(\"predicted labels\")\n",
    "plt.ylabel(\"actual labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on test data\n",
    "mse_test, x_hat_test = predict_and_compute_mse(x_test, model)\n",
    "y_pred_test = mse_test > threshold\n",
    "\n",
    "cmat = confusion_matrix(y_test.to_numpy(), y_pred_test)\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(cmat, annot=True, xticklabels=[\"non fraud\", \"fraud\"], yticklabels=[\"non fraud\", \"fraud\"])\n",
    "plt.xlabel(\"predicted labels\")\n",
    "plt.ylabel(\"actual labels\")\n",
    "\n",
    "print(\"Test data size: {}\".format(y_pred_test.shape[0]))\n",
    "print(\"Suspicious: {}\".format(sum(y_pred_test)))\n",
    "\n",
    "detection_rate = sum(y_pred_test) / y_pred_test.shape[0]\n",
    "hit_rate = sum(y_pred_test * y_test) / sum(y_pred_test)\n",
    "\n",
    "print(\"detection rate: {}, hit rate: {}\".format(detection_rate, hit_rate))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blissey",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b82058e73022bd04f30eb0beaf30411d92beda4b25c136820f4a8f727f7661e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
